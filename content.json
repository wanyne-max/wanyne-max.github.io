{"pages":[{"title":"关于我","text":"被酒莫惊春睡重 赌书消得泼茶香 当时只道是寻常","link":"/about/index.html"}],"posts":[{"title":"MySQL比较运算符","text":"最近在看《MySQL必知必会》，其中对于mysql中运算符的运用有较多讲解，现做部分笔记 MySQL 运算符 运算符 描述 备注 &gt; / &gt;= 大于 / 大于等于 &lt; / &lt;= 小于 / 小于等于 &lt;&gt; / != 不等于 两者都是不等于，和 &lt;=&gt; 运算符有区别 &lt;=&gt; NULL-safe 等于运算符 在某些场景下特别有用 = 等于 MySQL 比较在 MySQL 中，NULL 和 NULL 是没法做比较的，也就是 NULL = NULL 的返回值是 NULL。 1234567891011121314MariaDB [mybatis]&gt; SELECT NULL = NULL;+-------------+| NULL = NULL |+-------------+| NULL |+-------------+MariaDB [mybatis]&gt; SELECT NULL != NULL;+--------------+| NULL != NULL |+--------------+| NULL |+--------------+ &gt; &gt;= &lt; &lt;= = != &lt;&gt; 都是如上同理。要判断是不是 NULL，可以使用 IS NULL / IS NOT NULL 进行判断。 1234567891011121314MariaDB [mybatis]&gt; SELECT NULL IS NULL;+--------------+| NULL IS NULL |+--------------+| 1 |+--------------+MariaDB [mybatis]&gt; SELECT NULL IS NOT NULL;+------------------+| NULL IS NOT NULL |+------------------+| 0 |+------------------+ 这样子的结果是对的，但是还存在一种情况，我们不知道要比较的值是不是 NULL，这时候就需要 &lt;=&gt;。 123456789101112131415161718192021222324252627282930MariaDB [mybatis]&gt; SELECT NULL &lt;=&gt; NULL;+---------------+| NULL &lt;=&gt; NULL |+---------------+| 1 |+---------------+MariaDB [mybatis]&gt; SELECT 1 &lt;=&gt; NULL;+------------+| 1 &lt;=&gt; NULL |+------------+| 0 |+------------+MariaDB [mybatis]&gt; SELECT !(1 &lt;=&gt; NULL);+---------------+| !(1 &lt;=&gt; NULL) |+---------------+| 1 |+---------------+MariaDB [mybatis]&gt; SELECT !(NULL &lt;=&gt; NULL);+------------------+| !(NULL &lt;=&gt; NULL) |+------------------+| 0 |+------------------+ 有时候需要在 WHERE 里面写 name = ${name} AND type = 1，你想要查询 name 这个字段为 NULL 的记录并且 type 等于 1，但是发现不管怎么查询都是 Empty set。 如果换成 name &lt;=&gt; ${name} AND type = 1 这样子 name 的值传入 NULL，也可以查询，也就是查询 name 为 NULL（相当于 name IS NULL） 并且 type 等于 1 的记录。 name 传入的值非 NULL，例如 AAA，也就会查询 name 等于 AAA 并且 type 等于 1 的记录。 当然了，你也可以在程序里面判断 name 是不是 NULL，如果是 NULL 的话使用 name IS NULL AND type = 1 进行查询。 不是 NULL，就使用 name = ${name} AND type =1 进行查询。","link":"/2021/10/08/MySQL%E6%AF%94%E8%BE%83%E8%BF%90%E7%AE%97%E7%AC%A6/"},{"title":"UTC-UT-GMT  时区和时间戳","text":"格林尼治平时（Greenwich Mean Time），简称 GMT 世界时（Universal Time），简称 UT 协调世界时（Coordinated Universal Time），简称 UTC UTC, UT, GMT 三者出现的先后顺序： GMT -&gt; UT -&gt; UTC，我们可以把 GMT 和 UTC 看作一样的。 GMT 和 UTC 都是用 秒 数来计算的。 时区 全球划分为 24 个时区 时区可以用 UTC 表示，范围为 UTC-12 — UTC-11 — UTC-1 — UTC — UTC-1 — UTC+11 — UTC+12，依次增加 相差多少个时区，就是相差多少个小时 时区可以按 区域/位置 的格式表示，就可以得到一个独有的名称（时区有很多种表示方式） 以 中国时区 为例。 China Standard Time (CST), UTC +8、 无夏令时，全年 UTC 偏移量不变 中国的 IANA 时区标识符为 Asia/Shanghai。 时间戳 时间戳（Timestamp）是指字符串或编码信息用于辨识记录下来的时间日期。国际标准为 ISO 8601 时间戳是从 协调世界时（UTC） 1970 年 1 月 1 日 0 时 0 分 0 秒 起至现在的总秒数，不考虑闰秒 时间戳是用无符号整数表示 时间戳 和 UTC 进行转换，UTC 和 时区 进行转换，因此 时间戳 也可以和 UTC 进行转换 有 秒级（10 位）， 毫秒级（13 位） 的时间戳，也有纳米级（19 位） 的时间戳，如 Java 就可以处理到纳米级 本地时间是指当前操作系统设定的时区。例如北京时区是东8区，则本地时间：2015-04-19 12:20:00 实际上就是UTC+8:00时区的时间：2015-04-19 12:20:00 UTC+8:00 而此刻的格林威治标准时间与北京时间差了8小时，也就是UTC+0:00时区的时间应该是：2015-04-19 04:20:00 UTC+0:00 原文链接：https://blog.csdn.net/zheng_lan_fang/article/details/79448965 因为时区的关系，由于没设置使用者的时区，所以就会看到在一些系统上会出现时间慢了 8 个小时的现象（以北京时区为例） 不同的编程语言可以通过设置的方式来调整时区 不同的编程语言 格式化 时间的方式也不同（如：yyyy-mm-dd hh:mm:ss），为确保统一，我们可以使用时间戳（mysql，Java，JavaScript 存放时间都用 时间戳，就不会产生写入和读出不一致了。","link":"/2021/08/08/UTC-UT-GMT%20%20%E6%97%B6%E5%8C%BA%E5%92%8C%E6%97%B6%E9%97%B4%E6%88%B3/"},{"title":"blog搭建（记录踩过的坑）","text":"前两天整理资料的时候看到以前准备搭建的博客，想着趁空闲时间试着搞一个。每次搞个什么东西都磨磨蹭蹭的，这次索性直接莽 先是查找了市面上的常见架构，本来贼心动wordpress，但是看着太麻烦，其实是要用服务器太贵，直接放弃 最后选择的是hexo+lcarus搭建静态博客的方法，然后将博客push到github上存储。 （一）搭建环境 1、安装node.js首先要先安装node.js：https://github.com/hexojs/hexo/issues （注意要选择长期支持版 较稳定） 安装较简单，安装目标目录可以自定义，如果C盘较小就换到其他盘 2、安装gitgit 官方网站：https://git-scm.com/ 你如果不会用的话,可以去这个廖雪峰老师的网站: https://www.liaoxuefeng.com/wiki/896043488029600 输入 node -v npm -v git –version看一下版本号，若正常输出则说明成功了 3、创建GitHub Pages (仓库)在你的github主页, ​ 点击右上角 + 号 &gt; New repository ​ Repository name 中输入 你的用户名.github.io(若不这样，则会404) ​ 勾选 “Initialize this repository with a README” ​ Description 选填 点Create repository后你的博客地址就生成了 地址为: https://用户名.github.io （二）安装Hexo 1、安装打开终端 执行 npm install hexo-cli -g 全局安装Hexo. 2、创建博客创建blog文件夹用于存放博客md cd blog 进入博客目录 npm install 安装依赖 执行 npm install hexo-cli -g 全局安装Hexo. hexo s 启动服务 （三）选择主题在blog初始化的时候hexo就默认下载了landscape主题，对比了很多款，我现在正在用的这款是icarus，也可以到hexo的主题列表里面自己选择 https://hexo.io/themes/ 下载 进入博客根目录,打开git bash git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus 下载完成之后需要修改配置在blog文件夹下 _config.yml文件 所有配置基本都在这里 找到theme: landscape 修改为theme: icarus 重启服务即可(hexo clean \\ hexo g \\ hexo s). （四）开始记录hexo默认是使用的markdown，执行hexo new 文章名 默认会在./source/_posts/ 文件夹下创建.md文件 同理 也可以把自己已经写好的.md文件放到这个目录下，然后执行 hexo g &amp;&amp; hexo s 打开浏览器就能看到编译好的html了 最后使用hexo d将修改后的内容push到GitHub上 常见问题修改了主题之后执行 hexo server可能会有如下报错 这是因为icarus主题所需的依赖没有安装. 按照提示安装依赖(类似如下) npm install –save bulma-stylus@0.8.0 hexo-component-inferno@^0.4.0 hexo-renderer-inferno@^0.1.3 inferno@^7.3.3 inferno-create-element@^7.3.3 （五）hexo常用命令 clean Remove generated files and cache. config Get or set configurations. deploy Deploy your website. generate Generate static files. help Get help on a command. init Create a new Hexo folder. list List the information of the site migrate Migrate your site from other system to Hexo. new Create a new post. publish Moves a draft post from _drafts to _posts folder. render Render files with renderer plugins. server Start the server. version Display version information. （六）参考资料https://blog.csdn.net/marvine/article/details/89816846 https://blog.csdn.net/zemprogram/article/details/104288872 https://blog.csdn.net/ye17186/article/details/111564883 https://gitee.com/W4j1e/hexo-douban-list2","link":"/2021/08/05/blog%E6%90%AD%E5%BB%BA%EF%BC%88%E8%AE%B0%E5%BD%95%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91%EF%BC%89/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/08/05/hello-world/"},{"title":"http和https的那些七七八八","text":"搭博客的这段时间，发现有些博客地址前面有个不安全的标志，而大佬们的博客前面都是一个锁。后来百度的才知道，原来二者所用的协议不一样： 不安全的标志是因为用的是Http协议，访问的是80端口，传输的数据如果不自己进行加密，传输的是明文 大佬们用的是Https协议，访问的是443端口，传输的数据进行了加密，安全性更好 Http协议与Https协议Http协议超文本传输协议（英文：HyperText Transfer Protocol，缩写：HTTP）是一种用于分布式、协作式和超媒体信息系统的应用层协议。HTTP是万维网的数据通信的基础，现在我们的网页浏览器，各种服务的接口，还有一些流应用都是基于Http协议的，在这里我就不赘述了，详情可以参考这篇博客，里面已经介绍的十分清楚了。 Https协议因为https协议涉及一些密码学的知识，先扫个盲 数据的加密与解密对称加密——服务器和客户端都有相同的密钥 对称加密：对称加密又叫做私钥加密，即信息的发送方和接收方使用同一个密钥去加密和解密数据。对称加密的特点是算法公开、加密和解密速度快，适合于对大数据量进行加密，但是安全性低，一旦私钥泄露，数据就有被盗取的风险。 其加密过程如下：明文 + 加密算法 + 私钥 =&gt; 密文解密过程如下： 密文 + 解密算法 + 私钥 =&gt; 明文 非对称加密——顾名思义服务器和客户端拥有的密钥不对等 非对称加密：非对称加密也叫做公钥加密。非对称加密与对称加密相比，其安全性更好。对称加密的通信双方使用相同的密钥，如果一方的密钥遭泄露，那么整个通信就会被破解。而非对称加密使用一对密钥，即公钥和私钥，且二者成对出现。私钥被自己保存，不能对外泄露。公钥指的是公共的密钥，任何人都可以获得该密钥。用公钥或私钥中的任何一个进行加密，用另一个进行解密。 被公钥加密过的密文只能被私钥解密，过程如下： 明文 + 加密算法 + 公钥 =&gt; 密文， 密文 + 解密算法 + 私钥 =&gt; 明文 被私钥加密过的密文只能被公钥解密，过程如下： 明文 + 加密算法 + 私钥 =&gt; 密文， 密文 + 解密算法 + 公钥 =&gt; 明文 由于加密和解密使用了两个不同的密钥，这就是非对称加密“非对称”的原因。非对称加密的缺点是加密和解密花费时间长、速度慢，只适合对少量数据进行加密。 Https协议传输原理HTTPS协议 = HTTP协议 + SSL/TLS协议，在HTTPS数据传输的过程中，需要用SSL/TLS对数据进行加密和解密，需要用HTTP对加密后的数据进行传输。https协议的基础是http协议，而且在一次https请求中，包含了两次http请求。 为了安全和灵活性，https同时使用了对称加密和非对称加密，用非对称加密传输密钥，用对称加密传输数据，这样一来，既可以防止他人拿到密钥，又减少了加密和解密花费的时间。下图展示了一次Https请求的流程： 一共分为8步，产生了两次http请求，期间有三个密钥客户端产生的随机密钥，服务器公钥，服务器私钥： client对server发起请求；第一次http请求 server端获取自己的公钥； server端将自己的公钥发给client端； client检验该公钥是否有效，无效则抛安全异常，有效则创建随机密钥，并用公钥加密随机密钥； client用随机密钥加密传输的请求，并将请求和用公钥加密后的随机密钥一起发给server；第二次http请求 server用自己的私钥解密随机密钥，得到随机密钥后，解密请求。 server对请求做出响应，将响应用随机密钥加密后，传给client端。 client端用随机密钥，解密出响应，并在浏览器上展示。 至此，一次https请求执行完毕。从中我们可以看到，私钥一直由服务器保存，我们传输的是公钥和客户端产生的随机密钥，所以只要私钥不被泄露，监听者是无法解密我们的请求与响应的。","link":"/2021/08/07/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%B8%83%E4%B8%83%E5%85%AB%E5%85%AB/"},{"title":"Springboot 注解","text":"一、注解详解@SpringBootApplication：申明让spring boot自动给程序进行必要的配置，这个配置等同于： @Configuration ，@EnableAutoConfiguration 和 @ComponentScan 三个配置。 @ResponseBody：表示该方法的返回结果直接写入HTTP response body中，一般在异步获取数据时使用，用于构建RESTful的api。在使用@RequestMapping后，返回值通常解析为跳转路径，加上@esponsebody后返回结果不会被解析为跳转路径，而是直接写入HTTP response body中。比如异步获取json数据，加上@Responsebody后，会直接返回json数据。该注解一般会配合@RequestMapping一起使用。 @Controller：用于定义控制器类，在spring项目中由控制器负责将用户发来的URL请求转发到对应的服务接口（service层），一般这个注解在类中，通常方法需要配合注解@RequestMapping。 @RestController：用于标注控制层组件(如struts中的action)，@ResponseBody和@Controller的合集。 @RequestMapping：提供路由信息，负责URL到Controller中的具体函数的映射。 @EnableAutoConfiguration：SpringBoot自动配置（auto-configuration）：尝试根据你添加的jar依赖自动配置你的Spring应用。例如，如果你的classpath下存在HSQLDB，并且你没有手动配置任何数据库连接beans，那么我们将自动配置一个内存型（in-memory）数据库”。你可以将@EnableAutoConfiguration或者@SpringBootApplication注解添加到一个@Configuration类上来选择自动配置。如果发现应用了你不想要的特定自动配置类，你可以使用@EnableAutoConfiguration注解的排除属性来禁用它们。 @ComponentScan：表示将该类自动发现扫描组件。个人理解相当于，如果扫描到有@Component、@Controller、@Service等这些注解的类，并注册为Bean，可以自动收集所有的Spring组件，包括@Configuration类。我们经常使用@ComponentScan注解搜索beans，并结合@Autowired注解导入。可以自动收集所有的Spring组件，包括@Configuration类。我们经常使用@ComponentScan注解搜索beans，并结合@Autowired注解导入。如果没有配置的话，Spring Boot会扫描启动类所在包下以及子包下的使用了@Service,@Repository等注解的类。 @Configuration：相当于传统的xml配置文件，如果有些第三方库需要用到xml文件，建议仍然通过@Configuration类作为项目的配置主类——可以使用@ImportResource注解加载xml配置文件。 @Import：用来导入其他配置类。 @ImportResource：用来加载xml配置文件。 @Autowired：自动导入依赖的bean @Service：一般用于修饰service层的组件 @Repository：使用@Repository注解可以确保DAO或者repositories提供异常转译，这个注解修饰的DAO或者repositories类会被ComponetScan发现并配置，同时也不需要为它们提供XML配置项。 @Bean：用@Bean标注方法等价于XML中配置的bean。放在方法的上面，而不是类，意思是产生一个bean,并交给spring管理。 @Value：注入Spring boot application.properties配置的属性的值。示例代码： @Inject：等价于默认的@Autowired，只是没有required属性； @Component：泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 @AutoWired：自动导入依赖的bean。byType方式。把配置好的Bean拿来用，完成属性、方法的组装，它可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作。当加上（required=false）时，就算找不到bean也不报错。 @Qualifier：当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用。@Qualifier限定描述符除了能根据名字进行注入，但能进行更细粒度的控制如何选择候选者，具体使用方式如下： @Resource(name=”name”,type=”type”)：没有括号内内容的话，默认byName。与@Autowired干类似的事。 二、注解列表@SpringBootApplication：包含了@ComponentScan、@Configuration和@EnableAutoConfiguration注解。其中 @ComponentScan：让spring Boot扫描到Configuration类并把它加入到程序上下文。 @Configuration ：等同于spring的XML配置文件；使用Java代码可以检查类型安全。 @EnableAutoConfiguration ：自动配置。 @ComponentScan ：组件扫描，可自动发现和装配一些Bean。 @Component可配合CommandLineRunner使用，在程序启动后执行一些基础任务。 @RestController：注解是@Controller和@ResponseBody的合集,表示这是个控制器bean,并且是将函数的返回值直 接填入HTTP响应体中,是REST风格的控制器。 @Autowired：自动导入。 @PathVariable：获取参数。 @JsonBackReference：解决嵌套外链问题。 @RepositoryRestResourcepublic：配合spring-boot-starter-data-rest使用。 三、JPA注解(Java持久层API)@Entity：@Table(name=”“)：表明这是一个实体类。一般用于jpa这两个注解一般一块使用，但是如果表名和实体类名相同的话，@Table可以省略 @MappedSuperClass:用在确定是父类的entity上。父类的属性子类可以继承。 @NoRepositoryBean:一般用作父类的repository，有这个注解，spring不会去实例化该repository。 @Column：如果字段名与列名相同，则可以省略。 @Id：表示该属性为主键。 @GeneratedValue(strategy = GenerationType.SEQUENCE,generator = “repair_seq”)：表示主键生成策略是sequence（可以为Auto、IDENTITY、native等，Auto表示可在多个数据库间切换），指定sequence的名字是repair_seq。 @SequenceGeneretor(name = “repair_seq”, sequenceName = “seq_repair”, allocationSize = 1)：name为sequence的名称，以便使用，sequenceName为数据库的sequence名称，两个名称可以一致。 @Transient：表示该属性并非一个到数据库表的字段的映射,ORM框架将忽略该属性。如果一个属性并非数据库表的字段映射,就务必将其标示为@Transient,否则,ORM框架默认其注解为@Basic。@Basic(fetch=FetchType.LAZY)：标记可以指定实体属性的加载方式 @JsonIgnore：作用是json序列化时将Java bean中的一些属性忽略掉,序列化和反序列化都受影响。 @JoinColumn（name=”loginId”）:一对一：本表中指向另一个表的外键。一对多：另一个表指向本表的外键。 @OneToOne、@OneToMany、@ManyToOne：对应hibernate配置文件中的一对一，一对多，多对一。 四、springMVC相关注解@RequestMapping：@RequestMapping(“/path”)表示该控制器处理所有“/path”的UR L请求。RequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。该注解有六个属性：params:指定request中必须包含某些参数值是，才让该方法处理。headers:指定request中必须包含某些指定的header值，才能让该方法处理请求。value:指定请求的实际地址，指定的地址可以是URI Template 模式method:指定请求的method类型， GET、POST、PUT、DELETE等consumes:指定处理请求的提交内容类型（Content-Type），如application/json,text/html;produces:指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回 @RequestParam：用在方法的参数前面。@RequestParamString a =request.getParameter(“a”)。 @PathVariable:路径变量。如 参数与大括号里的名字一样要相同。 五、全局异常处理@ControllerAdvice：包含@Component。可以被扫描到。统一处理异常。 @ExceptionHandler（Exception.class）：用在方法上面表示遇到这个异常就执行以下方法。 六、项目中具体配置解析和使用环境@MappedSuperclass： 1.@MappedSuperclass 注解使用在父类上面，是用来标识父类的 2.@MappedSuperclass 标识的类表示其不能映射到数据库表，因为其不是一个完整的实体类，但是它所拥有的属性能够映射在其子类对用的数据库表中 3.@MappedSuperclass 标识的类不能再有@Entity或@Table注解 @Column： 1.当实体的属性与其映射的数据库表的列不同名时需要使用@Column标注说明，该属性通常置于实体的属性声明语句之前，还可与 @Id 标注一起使用。 2.@Column 标注的常用属性是name，用于设置映射数据库表的列名。此外，该标注还包含其它多个属性，如：unique、nullable、length、precision等。具体如下： 1 name属性：name属性定义了被标注字段在数据库表中所对应字段的名称 2 unique属性：unique属性表示该字段是否为唯一标识，默认为false，如果表中有一个字段需要唯一标识，则既可以使用该标记，也可以使用@Table注解中的@UniqueConstraint 3 nullable属性：nullable属性表示该字段是否可以为null值，默认为true 4 insertable属性：insertable属性表示在使用”INSERT”语句插入数据时，是否需要插入该字段的值 5 updateable属性：updateable属性表示在使用”UPDATE”语句插入数据时，是否需要更新该字段的值 6 insertable和updateable属性：一般多用于只读的属性，例如主键和外键等，这些字段通常是自动生成的 7 columnDefinition属性：columnDefinition属性表示创建表时，该字段创建的SQL语句，一般用于通过Entity生成表定义时使用，如果数据库中表已经建好，该属性没有必要使用 8 table属性：table属性定义了包含当前字段的表名 9 length属性：length属性表示字段的长度，当字段的类型为varchar时，该属性才有效，默认为255个字符 10 precision属性和scale属性：precision属性和scale属性一起表示精度，当字段类型为double时，precision表示数值的总长度，scale表示小数点所占的位数 具体如下： 1.double类型将在数据库中映射为double类型，precision和scale属性无效 2.double类型若在columnDefinition属性中指定数字类型为decimal并指定精度，则最终以columnDefinition为准 3.BigDecimal类型在数据库中映射为decimal类型，precision和scale属性有效 4.precision和scale属性只在BigDecimal类型中有效 3.@Column 标注的columnDefinition属性: 表示该字段在数据库中的实际类型.通常 ORM 框架可以根据属性类型自动判断数据库中字段的类型,但是对于Date类型仍无法确定数据库中字段类型究竟是DATE,TIME还是TIMESTAMP.此外,String的默认映射类型为VARCHAR,如果要将 String 类型映射到特定数据库的 BLOB 或TEXT字段类型. 4.@Column标注也可置于属性的getter方法之前 @Getter和@Setter（Lombok） @Setter：注解在属性上；为属性提供 setting 方法 @Getter：注解在属性上；为属性提供 getting 方法 @Data：注解在类上；提供类所有属性的 getting 和 setting 方法，此外还提供了equals、canEqual、hashCode、toString 方法 @Setter：注解在属性上；为属性提供 setting 方法 @Getter：注解在属性上；为属性提供 getting 方法 @Log4j2 ：注解在类上；为类提供一个 属性名为log 的 log4j 日志对象，和@Log4j注解类似 @NoArgsConstructor：注解在类上；为类提供一个无参的构造方法 @AllArgsConstructor：注解在类上；为类提供一个全参的构造方法 @EqualsAndHashCode:默认情况下，会使用所有非瞬态(non-transient)和非静态(non-static)字段来生成equals和hascode方法，也可以指定具体使用哪些属性。 @toString:生成toString方法，默认情况下，会输出类名、所有属性，属性会按照顺序输出，以逗号分割。 @NoArgsConstructor, @RequiredArgsConstructor 和 @AllArgsConstructor无参构造器、部分参数构造器、全参构造器，当我们需要重载多个构造器的时候，只能自己手写了 @NonNull：注解在属性上，如果注解了，就必须不能为Null @val:注解在属性上，如果注解了，就是设置为final类型，可查看源码的注释知道 当你在执行各种持久化方法的时候，实体的状态会随之改变，状态的改变会引发不同的生命周期事件。这些事件可以使用不同的注释符来指示发生时的回调函数。 @javax.persistence.PostLoad：加载后。 @javax.persistence.PrePersist：持久化前。 @javax.persistence.PostPersist：持久化后。 @javax.persistence.PreUpdate：更新前。 @javax.persistence.PostUpdate：更新后。 @javax.persistence.PreRemove：删除前。 @javax.persistence.PostRemove：删除后。 1）数据库查询 @PostLoad事件在下列情况下触发： 执行EntityManager.find()或getreference()方法载入一个实体后。 执行JPQL查询后。 EntityManager.refresh()方法被调用后。 2）数据库插入 @PrePersist和@PostPersist事件在实体对象插入到数据库的过程中发生： @PrePersist事件在调用persist()方法后立刻发生，此时的数据还没有真正插入进数据库。 @PostPersist事件在数据已经插入进数据库后发生。 3）数据库更新 @PreUpdate和@PostUpdate事件的触发由更新实体引起： @PreUpdate事件在实体的状态同步到数据库之前触发，此时的数据还没有真正更新到数据库。 @PostUpdate事件在实体的状态同步到数据库之后触发，同步在事务提交时发生。 4）数据库删除 @PreRemove和@PostRemove事件的触发由删除实体引起： @PreRemove事件在实体从数据库删除之前触发，即在调用remove()方法删除时发生，此时的数据还没有真正从数据库中删除。 @PostRemove事件在实体从数据库中删除后触发。","link":"/2022/01/13/springboot%E6%B3%A8%E8%A7%A3/"},{"title":"为什么redis这么快","text":"最近在看一些关于redis的知识点，以前只知道它是一个非关系型数据库，适合用来做缓存，并且查询速度很快，但是它为什么这么快呢？ 1.redis是单线程的Redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，比如在很长的列表后面添加一个元素，在hash当中添加或者删除一个对象的时候，这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。而单线程，就不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。 不过这里又引申了一个问题，理论上来说多线程能更好的提高程序的运行效率，那为什么redis单线程还这么快呢？ 因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈。 并且redis是将所有的数据放在内存中的，所以说使用单线程去操作效率就是最高的，多线程（CPU上下文会切换：耗时的操作！），对于内存系统来说，如果没有上下文切换效率就是最高的，多次读写都是在一个CPU上的，在内存存储数据情况下，单线程就是最佳的方案。 2.使用IO多路复用，非阻塞IO2.1为什么要使用I/O多路复用技术当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，就会阻塞在 accept() 函数，这导致其他客户端无法和 Redis 建立连接。 类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。这就导致 Redis 整个线程阻塞，无法处理。 2.2 什么是IO多路复用技术Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中,内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。下图是IO多路复用的一个大致的模型图。","link":"/2021/08/26/%E4%B8%BA%E4%BB%80%E4%B9%88redis%E8%BF%99%E4%B9%88%E5%BF%AB/"},{"title":"域名为什么可以以 . 结尾","text":"奇怪的知识增加了。 . 是根域名。访问所有域名理论上都是由根域名开始解析的。 比如访问 http://www.cctv.com 这个网址，计算机先知道这个网址对应的ip才能访问。所以要做一次解析，也就是找到 http://www.cctv.com 对应的IP，这个过程叫“DNS解析”. 这个过程怎么进行呢?分 4 步, 计算机先询问 “.”根域名服务器, “管理com域名解析服务器在哪里?” 得到”com域名解析服务器”的地址，再去询问”管理cctv的域名解析服务器在哪里?” 得到”cctv域名解析服务器”的地址，再去询问”www对应的服务器在哪里?” http://www.cctv.com 的地址 GET! 于是我们发现，所有的网址的解析都需要先去访问这个根域名服务器，为了优化输入增加效率，许多浏览器就省略掉它了，但是在DNS协议里面，还是会默默地把这个“.”加上的。","link":"/2021/08/07/%E5%9F%9F%E5%90%8D%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AF%E4%BB%A5%E4%BB%A5%20.%20%E7%BB%93%E5%B0%BE/"},{"title":"如何修复失败的Git提交","text":"在使用 Git 的时候，大家都碰到过忘记添加文件或是忘记写注释等等糟心的情况。幸运的是，Git 中有一些命令可以帮助处理这些常见的情况，下面列出常见的解决方法。 1.修改提交信息在提交消息的时候你发现了提交内容错误。这个是可以修改的： git commit --amend -m &quot;new message&quot; 2.添加文件到最后一次提交更改已经提交，但又忘记添加文件了。没问题，我们仍然可以将文件添加到这次提交中： git add &lt;file_name&gt; git commit --amend HEAD~1 3.撤消提交如果要撤消最近一次提交但保留更改，可执行以下操作： git reset --soft HEAD~1 如果要撤消提交和更改，可执行以下操作：注意，确定是要丢弃更改。 git reset --hard HEAD~1 还有一种情况是，如果要撤消所有的本地更改，则可以重置为分支的原始版本： git reset --hard origin/&lt;branch_name&gt; 如果要撤消提交而不修改现有历史记录，则可以使用 git revert，此命令通过创建新的提交来撤消提交。 git revert HEAD 如果你刚解决了冲突，完成了合并，并且推送到了原始版本。撤消已经推送到远程分支的合并提交的安全方法是使用 git revert 命令：(其中commit_id 是要还原的合并提交 id。) git revert -m 1 &lt;commit_id&gt; 注意要点： 可以撤消任意数量的提交。例如：git reset HEAD~3（返回 HEAD 之前的 3 个提交)；git reset --hard &lt;commit_id&gt;（返回特定的提交）。 如果尚未推送提交，并且你不想引入糟糕的提交到远程分支，可以使用 git reset。 使用 git revert 还原已经推送到远程分支的合并提交。 使用 git log 查看提交历史。","link":"/2021/08/08/%E5%A6%82%E4%BD%95%E4%BF%AE%E5%A4%8D%E5%A4%B1%E8%B4%A5%E7%9A%84Git%E6%8F%90%E4%BA%A4/"},{"title":"如何嵌入B站视频","text":"B 站的网页版已经提供了内嵌的 iframe 代码，我们只需要一键复制后就可以直接使用。 原版链接&lt;iframe src=&quot;//player.bilibili.com/player.html?aid=60731116&amp;bvid=BV1qt411j7fV&amp;cid=106015992&amp;page=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt; &lt;/iframe&gt; 自适应版这样原版链接一般来说是够用了，但是它也有问题，我们能不能搞一种更通用的引用方式呢？ &lt;div style=&quot;position: relative; padding: 30% 45%;&quot;&gt; &lt;iframe style=&quot;position: absolute; width: 100%; height: 100%; left: 0; top: 0;&quot; src=&quot;//player.bilibili.com/player.html?aid=60731116&amp;bvid=BV1qt411j7fV&amp;cid=106015992&amp;page=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt; &lt;/div&gt; 参数说明： key 说明 aid 之前 B 站使用的 AV 号 bvid 目前的 BV 号 page 第几个视频, 起始下标为 1 (默认值也是为 1)就是 B 站视频, 选集里的, 第几个视频 as_wide 是否宽屏 【1: 宽屏, 0: 小屏】 high_quality 是否高清 【1: 高清(最高1080p) / 0: 最低视频质量(默认)】 danmaku 是否开启弹幕 【1: 开启(默认), 0: 关闭】","link":"/2021/08/07/%E5%A6%82%E4%BD%95%E5%B5%8C%E5%85%A5B%E7%AB%99%E8%A7%86%E9%A2%91/"},{"title":"常用的一些git操作命令","text":"远程克隆git clone XXXX.git 克隆远程指定分支git clone -b 分支名 XXXX.git 创建本地分支git branch 分支名 删除本地分支git branch -d 分支名 查看远程分支git branch -a 删除远程分支git branch -r -d origin/jinsong git push origin --delete 分支名 切换到分支git checkout 分支名 查看所在分支git branch -a 查看所有修改了还没有add的文件git diff 查看单个修改了还没有add的文件git diff 文件名 add所有文件git add -A add某个文件git add 文件全名 commit操作修改了文件必须先add才能commit git commit -m \"提交的描述信息\" 拉取远程分支到本地push前最好先用pull更新本地代码 git pull origin 分支名：分支名 （前一个是远程分支名，后一个是本地分支名） git pull origin 分支名（远程和本地分支同名） 推送本地分支到远程必须本地已经切换到“分支名” git push origin 分支名：分支名 （前一个是本地分支名，后一个是会在远程生成的分支名，通常都用同一个名字） git push origin 分支名 （本地和远程分支同名） 远程已有“分支名”并且已经关联本地“分支名”且本地已经切换到“分支名”git push 远程已有“分支名”但未关联本地“分支名”且本地已经切换到“分支名”git push -u origin/分支名 查看远程仓库信息git remote -v/分支名 本地添加新的远程仓库，远程仓库是空的git remote add 给远程仓库在本地起个名字 XXXX.git 推送本地分支到对应的远程仓库git push 远程仓库名字 分支名 关联本地和远程分支git branch --set-upstream-to=origin/远程分支名 本地分支名 查看版本号，回滚到指定版本，推送到远程git log git reset --hard 版本号 git push -f origin 分支名","link":"/2021/08/06/%E5%B8%B8%E7%94%A8%E7%9A%84git%E6%93%8D%E4%BD%9C/"},{"title":"正则表达式笔记","text":"正则过于重要（最近越来越多用到：Java的split函数、js、nginx的配置、Linux），所以一边学一边记录下。 工具/网站安利 RegExp Tester：一个用于测试的chrome扩展，体积小且方便。 regexone：交互式学习和练习正则表达式的网站。 基础语法(PS:因为我就看会了这点，有不对的还请各位大佬指出，也可能手抖敲错了) 元字符 \\b：代表着单词的开头或结尾，也就是单词的分界处，它只匹配一个位置。 \\w：匹配字母或数字或下划线或汉字。 \\d：匹配数字，可以代替0到9之间的任何数字。 . ：匹配任何单个字符（字母，数字，空格，所有内容），实际上会覆盖句号字符的匹配，因此，为了专门匹配句号，使用斜杠\\来使句号转义。 \\s：匹配任意的空白符。 ^：匹配字符串的开始。 $：匹配字符串的结束。 ()：小括号来指定子表达式(也叫做分组)，然后可以对这个表达式指定各项操作。 转义查找元字符本身需要\\转义，例： regtest\\.py 匹配 regtest.py。 C:\\\\Windows 匹配 C:\\Windows。 反义 \\B：匹配不是单词开头或结束的位置。 \\W：匹配任意不是字母，数字，下划线，汉字的字符。 \\D：匹配任意非数字的字符。 \\S：匹配任意不是空白符的字符。 [\\^x]：匹配除了x以外的任意字符。 [\\^aeiou]：匹配除了aeiou这几个字母以外的任意字符。 例： \\S+ ：匹配不包含空白符的字符串。 &lt;a[^&gt;]+&gt; ：匹配用尖括号括起来的以a开头的字符串。 重复 * ：重复零次或更多次D + ：重复一次或更多次 ? ：重复零次或一次 {n}：重复n次 {n,}：重复n次或更多次 {n,m}：重复n到m次 例： Windows\\d+ ：匹配Windows后面跟1个或更多数字。 \\^\\w+ ：匹配 一行的第一个单词（或整个字符串的第一个单词）。 字符范围[]表示法中： -：表示字符范围。 ^ ：表示不要某几个字符。 例： [0-6] ：仅会匹配从零到六个的任何一位数字字符。 [^ np] ：将仅匹配任何单个字符，但字母n至p除外。 后向引用、分组、捕获默认情况下，每个分组会自动拥有一个组号，规则 是：从左向右，以分组的左括号为标志，第一个出现的分组的组号为1，第二个为2，以此类推。 捕获 (exp) ：匹配exp,并捕获文本到自动命名的组里。 (?exp) ：匹配exp,并捕获文本到名称为name的组里，也可以写成 (?’name’exp)。 (?:exp) ：匹配exp,不捕获匹配的文本，也不给此分组分配组号。（PS：不会改变正则表达式的处理方式，只是这样的组匹配的内容 不会像前两种那样 被捕获到某个组里面，也不会拥有组号。 零宽断言 (?=exp) ：匹配exp前面的位置 (?&lt;=exp) ：匹配exp后面的位置 (?!exp) ：匹配后面跟的不是exp的位置 (?&lt;!exp) ：匹配前面不是exp的位置 注释 (? #comment) ：这种类型的分组不对正则表达式的处理产生任何影响，用于提 供注释让人阅读 懒惰匹配匹配尽可能少的字符 *? ：重复任意次，但尽可能少重复 +? ：重复1次或更多次，但尽可能少重复 ??：重复0次或1次，但尽可能少重复 {n,m}?：重复n到m次，但尽可能少重复 {n,}?：重复n次以上，但尽可能少重复 常用的部分正则表达式整数或者小数：^[0-9]+\\.{0,1}[0-9]{0,2}$。 只能输入数字：^[0-9]*$。 只能输入n位的数字：^\\d{n}$。 只能输入至少n位的数字：^\\d{n,}$。 只能输入m到n位的数字：^\\d{m,n}$。 只能输入零和非零开头的数字：^(0|[1-9][0-9]*)$。 只能输入有两位小数的正实数：^[0-9]+(.[0-9]{2})?$。 只能输入有1到3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$。 只能输入非零的正整数：^\\+?[1-9][0-9]*$。 只能输入非零的负整数：^\\-[1-9][]0-9″*$。 只能输入长度为3的字符：^.{3}$。 只能输入由26个英文字母组成的字符串：^[A-Za-z]+$。 只能输入由26个大写英文字母组成的字符串：^[A-Z]+$。 只能输入由26个小写英文字母组成的字符串：^[a-z]+$。 只能输入由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$。 只能输入由数字、26个英文字母或者下划线组成的字符串：^\\w+$。 验证用户密码：^[a-zA-Z]\\w{5,17}$。 正确格式为：以字母开头，长度在6~18之间，只能包含字符、数字和下划线。验证是否含有^%&amp;’,;=?$\\等字符：[^%&amp;',;=?$\\x22]+。 只能输入汉字：^[\\u4e00-\\u9fa5]{0,}$。 验证Email地址：^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$。 验证InternetURL：^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&amp;=]*)?$。 123验证电话号码：^(\\(\\d{3,4}-)|\\d{3.4}-)?\\d{7,8}$。正确格式为：XXX-XXXXXXX、XXXX-XXXXXXXX、XXX-XXXXXXX、XXX-XXXXXXXX、XXXXXXX和XXXXXXXX。 验证身份证号（15位或18位数字）：^\\d{15}|\\d{18}$。 12345验证一年的12个月：^(0?[1-9]|1[0-2])$。正确格式为：”01″～”09″和”1″～”12″。验证一个月的31天：^((0?[1-9])|((1|2)[0-9])|30|31)$正确格式为；”01″～”09″和”1″～”31″。 匹配中文字符的正则表达式： [\\u4e00-\\u9fa5]。 匹配双字节字符(包括汉字在内)：[^\\x00-\\xff]。 应用：计算字符串的长度（一个双字节字符长度计2，ASCII字符计1）String.prototype.len=function(){return this.replace(/[^\\x00-\\xff]/g,”aa”).length;} 匹配空行的正则表达式：\\n[\\s| ]*\\r 匹配html标签的正则表达式：&lt;(.*)&gt;(.*)&lt;\\/(.*)&gt;|&lt;(.*)\\/&gt; 12345678910111213匹配首尾空格的正则表达式：(^\\s*)|(\\s*$)应用：javascript中没有像vbscript那样的trim函数，我们就可以利用这个表达式来实现，如下：String.prototype.trim = function(){return this.replace(/(^\\s*)|(\\s*$)/g, “”);}利用正则表达式分解和转换IP地址：下面是利用正则表达式匹配IP地址，并将IP地址转换成对应数值的Javascript程序：function IP2V(ip){re=/(\\d+)\\.(\\d+)\\.(\\d+)\\.(\\d+)/g //匹配IP地址的正则表达式if(re.test(ip)){return RegExp.$1*Math.pow(255,3))+RegExp.$2*Math.pow(255,2))+RegExp.$3*255+RegExp.$4*1}else{throw new Error(“Not a valid IP address!”)}}//上面的程序直接用split函数来分解var ip=”10.100.20.168″ip=ip.split(“.”)alert(“IP值是：”+(ip[0]*255*255*255+ip[1]*255*255+ip[2]*255+ip[3]*1)) 匹配Email地址的正则表达式：\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)* 匹配网址URL的正则表达式：http://([\\w-]+\\.)+[\\w-]+(/[\\w- ./?%&amp;=]*)? 利用正则表达式限制网页表单里的文本框输入内容：用正则表达式限制只能输入中文： onkeyup=”value=value.replace(/[^\\u4E00-\\u9FA5]/g,”)” onbeforepaste=”clipboardData.setData(‘text’,clipboardData.getData(‘text’).replace(/[^\\u4E00-\\u9FA5]/g,”))” 用正则表达式限制只能输入全角字符： onkeyup=”value=value.replace(/[^\\uFF00-\\uFFFF]/g,”)” onbeforepaste=”clipboardData.setData(‘text’,clipboardData.getData(‘text’).replace(/[^\\uFF00-\\uFFFF]/g,”))” 用正则表达式限制只能输入数字： onkeyup=”value=value.replace(/[^\\d]/g,”) “onbeforepaste=”clipboardData.setData(‘text’,clipboardData.getData(‘text’).replace(/[^\\d]/g,”))” 用正则表达式限制只能输入数字和英文： onkeyup=”value=value.replace(/[\\W]/g,”) “onbeforepaste=”clipboardData.setData(‘text’,clipboardData.getData(‘text’).replace(/[^\\d]/g,”))” 123匹配中文字符的正则表达式： [\\u4e00-\\u9fa5]匹配双字节字符(包括汉字在内)： [^\\x00-\\xff]用来计算字符串的长度（一个双字节字符长度计2，ASCII字符计1）匹配空白行的正则表达式：\\n\\s*\\r 可以用来删除空白行匹配HTML标记的正则表达式（仅对部分简单情况适用）：&lt;(\\S*?)[^&gt;]*&gt;.*?|&lt;.*? /&gt; 匹配首尾空白字符的正则表达式：^\\s*|\\s*$ 可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式匹配Email地址的正则表达式：\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)* 表单验证时很实用匹配网址URL的正则表达式：[a-zA-z]+://[^\\s]* 匹配帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]{4,15}$ 表单验证时很实用匹配国内电话号码：\\d{3}-\\d{8}|\\d{4}-\\d{7} 匹配形式如 0511-4405222 或 021-87888822 匹配腾讯QQ号：[1-9][0-9]{4,} 从10000开始匹配中国邮政编码(中国邮政编码为6位数字)：[1-9]\\d{5}(?!\\d) 匹配ip地址：((2[0-4]\\d|25[0-5]|[01]?\\d\\d?)\\.){3}(2[0-4]\\d|25[0-5]|[01]?\\d\\d?) 匹配正整数: ^-[1-9]\\d*$ 匹配负整数: ^-?[1-9]\\d*$ 匹配整数: ^[1-9]\\d*|0$ 匹配非负整数（正整数 + 0）: ^-[1-9]\\d*|0$ 匹配非正整数（负整数 + 0）: ^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*$ 匹配正浮点数: ^-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*)$ 匹配负浮点数: ^-?([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0)$ 匹配浮点数: ^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0$ 匹配非负浮点数（正浮点数 + 0）: ^(-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*))|0?\\.0+|0$ 匹配非正浮点数（负浮点数 + 0）: ^[A-Za-z]+$ (处理大量数据时有用，具体应用时注意修正匹配特定字符串) 匹配由26个英文字母组成的字符串: ^[A-Z]+$ 匹配由26个英文字母的大写组成的字符串: ^[a-z]+$ 匹配由26个英文字母的小写组成的字符串: ^[A-Za-z0-9]+$ Email : /^\\w+([-+.]\\w+)*@\\w+([-.]\\\\w+)*\\.\\w+([-.]\\w+)*$/ isEmail1 : /^\\w+([\\.\\-]\\w+)*\\@\\w+([\\.\\-]\\w+)*\\.\\w+$/; isEmail2 : /^.*@[^_]*$/; Phone : /^((\\(\\d{3}\\))|(\\d{3}\\-))?(\\(0\\d{2,3}\\)|0\\d{2,3}-)?[1-9]\\d{6,7}$/ Mobile : /^((\\(\\d{3}\\))|(\\d{3}\\-))?13\\d{9}$/","link":"/2021/08/22/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%AC%94%E8%AE%B0/"},{"title":"网站流量小知识","text":"名称 全称 作用 PV Page view 页面浏览量，用户每打开 1 个网站页面，记录 1 个 PV；用户多次打开同一页面，PV 值累计多次。 UV Unique visitor 网站独立访客；1 天内相同访客多次访问网站，只计算为 1 个独立访客 IP Internet Protocol 1 天之内（00:00 ~ 24:00），访问网站的不重复的 IP 数 VV Viedo view 一个统计周期内，视频被打开的次数","link":"/2021/08/06/%E7%BD%91%E7%AB%99%E6%B5%81%E9%87%8F%E5%B0%8F%E7%9F%A5%E8%AF%86/"},{"title":"设置[阅读全文]","text":"在首页显示一篇文章的部分内容，并提供一个链接跳转到全文页面是一个常见的需求。 NexT 提供三种方式来控制文章在首页的显示方式。 也就是说，在首页显示文章的摘录并显示 阅读全文 按钮，可以通过以下方法： 1、在文章中使用&lt;!– more –&gt; 手动进行截断，Hexo 提供的方式 推荐(也可使用&lt;escape&gt;&lt;!– more –&gt;&lt;/escape&gt;) 2、在文章的 front-matter 中添加 description，并提供文章摘录 3、自动形成摘要，在主题配置文件中添加： auto_excerpt: enable: true length: 150 默认截取的长度为 150 字符，可以根据需要自行设定 建议使用&lt;!– more –&gt;（即第一种方式），除了可以精确控制需要显示的摘录内容以外， 这种方式也可以让 Hexo 中的插件更好的识别。","link":"/2021/08/06/%E8%AE%BE%E7%BD%AE-%E9%98%85%E8%AF%BB%E5%85%A8%E6%96%87/"},{"title":"重写和重载的区别","text":"定义不同—重载是定义相同的方法名，参数不同；重写是子类重写父类的方法 范围不同—重载是在一个类中，重写是子类与父类之间的 多态不同—重载是编译时的多态性，重写是运行时的多态性 返回不同—重载对返回类型没有要求，而重写要求返回类型，有兼容的返回类型 参数不同—重载的参数个数、参数类型、参数顺序可以不同，而重写父子方法参数必须相同 修饰不同—重载对访问修饰没有特殊要求，重写访问修饰符的限制一定要大于被重写方法的访问修饰符","link":"/2021/10/15/%E9%87%8D%E5%86%99%E5%92%8C%E9%87%8D%E8%BD%BD%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"《MySQL必知必会》笔记1","text":"最近在看《MySQL必知必会》，现做部分笔记，这是第一章至第十章的内容 第一章 了解SQL数据库：保存有组织的数据的容器（通常是一个文件或一组文件） 表: 表名唯一，取决多个因素，如不同数据库的表可以同名 模式: 关于数据库和表的布局及特性的信息、 列: 表中的字段 行: 行(raw)和记录(record)很大程度可以等同，但行才是正确的术语 数据类型: 限制数据种类，帮助正确排序，磁盘优化方面的作用 主键（primary key）: 一列，其值可以唯一区分表中的行。 SQL （Structured Query Language）：结构化查询语言。 主键条件：1、每行都应有一个主键，所以其值不为null。 2、任意两行间的主键值不同。 主键通常是一列，但也可多列共同构成主键。 主键设置建议：1、不更新主键列中的值； 2、不重用主键列的值； 3、不在主键列中使用可能会更改的值。 SQL命令执行：1、命令在mysql&gt;之后输入； 2、命令用 ；或 \\g 结束，仅按Enter不执行命令； 3、输入 help 或 \\h 获取帮助； 4、输入 quit 或 exit 退出程序。 基本语句：12345678910111213141516171819202122232425myslq -u root -p;use Database;#SHOW相关SHOW databases;SHOW tables;SHOW columns FROM tables; -- 等于 describe &quot;tables&quot;;SHOW CREATE DATABASE db_name; 显示完整的建库语句SHOW CREATE TABLE tbl_name;SHOW [STORAGE] ENGINES#SELECT相关SELECT column_name1,column_name2 FROM table;SELECT *FROM tables;-- Distinct-- 不能部分使用DISTINCT，其应用于所有列而不是其前置列SELECT DISTINCT column_namw FROM table; -- Limit 从第零个开始后的5个 取的时候排列顺序是从零开始的。SELECT column_name FROM table_name LIMIT 5;-- 从第二个开始后的5个SELECT column_name FROM table_name LIMIT 2,5;-- OFFSET 限制两个，从第三为开始取SELECT column_name FROM table_name LIMIT 2 OFFSET 3; -- 使用全限定的表名 库：manxc 表：tagsSELECT tags.tid FROM manxc.tags; 排序检索数据关键字：ORDER BY 12SELECT column_name FROM table_name ORDER BY column_name; 默认升序，字母按A-Z排，数字从小到大； 注：排序中文时出现问题。解决方式： 1 修改数据库表字段： 对于包含中文的字段加上binary属性，使之作为二进制比较。 eg: 将name char(10) 改成 name char(10)binary 2 修改查询语句： 如果不想修改数据库中表字段属性的话，也可以在查询语句的order by部分使用 CONVERT函数。 eg: select * from pub_user_info u where u.sex='1' order by CONVERT(u.name USING GBK) asc; ps：数据库表结构一般在确定后就尽量不要去做改动，所以推荐使用第二种方法 升序（默认）：ASC降序：DESC 过滤数据关键字：WHERE（同时可与其它关键字组合） 123456789101112131415SELECT * FROM manxc.tags WHERE tags.tid BETWEEN 2 AND 9 ORDER BY tid DESC,tagname;操作符 说明= 等于&lt;&gt; 不等于!= 不等于&lt; 小于&lt;= 小于等于&gt; 大于&gt;= 大于等于BETWEEN 在指定的两个值之间此处可详见文章：MySQL比较运算符 eg: 12345678910mysql&gt; SELECT 2 BETWEEN 1 AND 3, 2 BETWEEN 3 and 1; -&gt; 1, 0 mysql&gt; SELECT 1 BETWEEN 2 AND 3; -&gt; 0 mysql&gt; SELECT 'b' BETWEEN 'a' AND 'c'; -&gt; 1 mysql&gt; SELECT 2 BETWEEN 2 AND '3'; -&gt; 1 mysql&gt; SELECT 2 BETWEEN 2 AND 'x-3'; -&gt; 0 WHERE 匹配字符加‘’；且其在执行匹配时默认不区分大小写； 123456mysql&gt; SELECT uid,username,state FROM manxc.user WHERE username='FLY';+-----+----------+-------+| uid | username | state |+-----+----------+-------+| 3 | fly | 0 |+-----+----------+-------+ 空值检查：IS NULL (空值是无值和0和空格不同) 12345678mysql&gt; SELECT uid,username,state FROM user WHERE password IS NULL LIMIT 3;+-----+----------+-------+| uid | username | state |+-----+----------+-------+| 8 | dfdg | NULL || 9 | dgdg | NULL || 10 | gdg | NULL |+-----+----------+-------+ 数据过滤操作符（operator） :用来联结或改变where子句的关键字。 AND 操作符 1234567891011mysql&gt; SELECT uid,username,state FROM USER WHERE state IS NULL AND uid &lt;= 13;+-----+-----------+-------+| uid | username | state |+-----+-----------+-------+| 8 | dfdg | NULL || 9 | dgdg | NULL || 10 | gdg | NULL || 11 | dgdgh | NULL || 12 | dgklds | NULL || 13 | dgkljdlkg | NULL |+-----+-----------+-------+ OR操作符： 123456789101112131415161718192021222324mysql&gt; SELECT uid,username,state FROM USER WHERE state IS NULL OR uid &lt;= 13;+-----+--------------+-------+| uid | username | state |+-----+--------------+-------+| 4 | test1 | 0 || 3 | fly | 0 || 5 | test2 | 0 || 6 | test3 | 1 || 7 | 1 | 1 || 8 | dfdg | NULL || 9 | dgdg | NULL || 10 | gdg | NULL || 11 | dgdgh | NULL || 12 | dgklds | NULL || 13 | dgkljdlkg | NULL || 14 | fdjwe | NULL || 15 | gkdlkg | NULL || 16 | dgdlkjg | NULL || 17 | fdglkdjg | NULL || 18 | gkldssjgdsas | NULL || 19 | dgjkljg | NULL || 20 | djglkdg | NULL || 21 | kgdlksgj | NULL |+-----+--------------+-------+ 混合使用时的顺序：在有多个or和and同时使用时，优先处理and，可以使用()提高优先级。 1234567891011121314151617181920212223242526272829303132333435mysql&gt; SELECT uid,username,state FROM USER WHERE (state IS NULL OR state =1) AND uid &lt;=10;+-----+----------+-------+| uid | username | state |+-----+----------+-------+| 6 | test3 | 1 || 7 | 1 | 1 || 8 | dfdg | NULL || 9 | dgdg | NULL || 10 | gdg | NULL |+-----+----------+-------+5 rows in set (0.00 sec)mysql&gt; SELECT uid,username,state FROM USER WHERE state IS NULL OR state =1 AND uid &lt;=10;+-----+--------------+-------+| uid | username | state |+-----+--------------+-------+| 6 | test3 | 1 || 7 | 1 | 1 || 8 | dfdg | NULL || 9 | dgdg | NULL || 10 | gdg | NULL || 11 | dgdgh | NULL || 12 | dgklds | NULL || 13 | dgkljdlkg | NULL || 14 | fdjwe | NULL || 15 | gkdlkg | NULL || 16 | dgdlkjg | NULL || 17 | fdglkdjg | NULL || 18 | gkldssjgdsas | NULL || 19 | dgjkljg | NULL || 20 | djglkdg | NULL || 21 | kgdlksgj | NULL |+-----+--------------+-------+16 rows in set (0.00 sec) 建议：使用具有AND和OR操作符的WHERE子句，都应该使用圆括号明确的分组，不用过分依赖计算次序，使用括号没有坏处且能消除歧义。 IN 操作符：where子句使用in操作符 1234567891011mysql&gt; SELECT uid,username,state FROM user WHERE state IN (0,1);+-----+----------+-------+| uid | username | state |+-----+----------+-------+| 4 | test1 | 0 || 3 | fly | 0 || 5 | test2 | 0 || 6 | test3 | 1 || 7 | 1 | 1 |+-----+----------+-------+5 rows in set (0.00 sec) IN 和 OR 有类似作用，此句表示查询state是0或1的。 IN操作符的优点：1、使用IN时，计算次序更容易管理（操作符少了，没那么多or） 2、IN操作符的语法更清楚且直观； 3、IN一般比OR的执行更快； 4、IN的最大优点时可以包含其它SELECT语句，使得能更动态的建立WHERE子句。 NOT 操作符：where子句中，not用来否定之后跟的条件。 12345678910111213141516171819mysql&gt; select * from tags where tid NOT IN (1,2,3,4,5,6,7,8,9,10);+-----+---------+| tid | tagname |+-----+---------+| 11 | 猎奇 || 12 | 少女 || 13 | 魔法 || 14 | 历史 || 15 | 机战 || 16 | 神魔 || 17 | 运动 || 18 | 励志 || 19 | 音乐 || 20 | 推理 || 21 | 美食 || 22 | 催泪 || 23 | 职场 || 26 | 搞笑 |+-----+---------+ 注：MySQL支持使用NOT对IN，BETWEEN，EXISTS子句取反。 统配符过滤关键字：like 统配符匹配： 1、百分号（%）通配符：表示任何字符出现任意次数，（任意字数的任意字符） 注： A.由配置方式，搜索时可以区分大小写的； B.注意尾空格，尾空格会干扰匹配，可在其前后都家%,或者使用函数。 2、下划线（_）: 任意的单个字符； 注：统配符的搜索处理比之前操作符的效率更低使用时： A.不要过度使用，能用其他操作符的，尽量用。 B.除非有绝对必要，不要把通配符放在搜索模式的开始处，这样是最慢的。 C.注意统配符放的位置。 12SELECT prod_id,prod_name FROM productsWHERE prod_name LIKE '%ton anvil'; 正则表达式搜索关键字：REGEXP 其后跟正则表达式 LIKE与REGEXP的区别： LIKE匹配整个列，如果匹配的文本在列值中出现，LIKE不会找到它，相应行也不会返回（除非使用统配符），而REGEXP可以在列值中进行匹配： 123456789101112mysql&gt; SELECT uid,username,password,state FROM user WHERE username LIKE &quot;test&quot;;Empty set (0.00 sec)mysql&gt; SELECT uid,username,password,state FROM user WHERE username REGEXP &quot;test&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 4 | test1 | 123 | 0 || 5 | test2 | 123 | 0 || 6 | test3 | 123 | 1 |+-----+----------+----------+-------+3 rows in set (0.05 sec) 注：MYSQL中正则匹配不区分大小写，如需区分可使用BINARY关键字，如WHERE prod-name REGEXP BINARY 'JetPack' 进行or匹配 使用“|”1234567891011121314mysql&gt; SELECT uid,username,password,state FROM user WHERE username REGEXP &quot;1|lk&quot;;+-----+-----------+----------+-------+| uid | username | password | state |+-----+-----------+----------+-------+| 4 | test1 | 123 | 0 || 7 | 1 | 1 | 1 || 13 | dgkljdlkg | NULL | NULL || 15 | gkdlkg | NULL | NULL || 16 | dgdlkjg | NULL | NULL || 17 | fdglkdjg | NULL | NULL || 20 | djglkdg | NULL | NULL || 21 | kgdlksgj | NULL | NULL |+-----+-----------+----------+-------+8 rows in set (0.00 sec) 匹配字符：使用“[ ]”匹配，相当于另一种形式的or；匹配其中的任意字符 123456789101112131415161718192021222324252627282930313233343536373839404142mysql&gt; SELECT uid,username,password,state FROM user WHERE username REGEXP &quot;test&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 4 | test1 | 123 | 0 || 5 | test2 | 123 | 0 || 6 | test3 | 123 | 1 || 22 | test4 | NULL | NULL || 23 | test5 | NULL | NULL || 24 | test6 | NULL | NULL |+-----+----------+----------+-------+6 rows in set (0.00 sec)mysql&gt; SELECT uid,username,password,state FROM user WHERE username REGEXP &quot;test[123]&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 4 | test1 | 123 | 0 || 5 | test2 | 123 | 0 || 6 | test3 | 123 | 1 |+-----+----------+----------+-------+3 rows in set (0.00 sec)mysql&gt; SELECT uid,username,password,state FROM user WHERE username REGEXP &quot;[123]test&quot;;Empty set (0.00 sec)mysql&gt; SELECT uid,username,password,state FROM user WHERE username REGEXP &quot;[test]&quot;;+-----+--------------+----------+-------+| uid | username | password | state |+-----+--------------+----------+-------+| 4 | test1 | 123 | 0 || 5 | test2 | 123 | 0 || 6 | test3 | 123 | 1 || 12 | dgklds | NULL | NULL || 14 | fdjwe | NULL | NULL || 18 | gkldssjgdsas | NULL | NULL || 21 | kgdlksgj | NULL | NULL || 22 | test4 | NULL | NULL || 23 | test5 | NULL | NULL || 24 | test6 | NULL | NULL |+-----+--------------+----------+-------+10 rows in set (0.00 sec) 加上“^”表非 123456789mysql&gt; SELECT uid,username,password,state FROM user WHERE username REGEXP &quot;test[^123]&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 22 | test4 | NULL | NULL || 23 | test5 | NULL | NULL || 24 | test6 | NULL | NULL |+-----+----------+----------+-------+3 rows in set (0.00 sec) 空格 12345678mysql&gt; SELECT uid,username,password,state FROM user WHERE username REGEXP &quot;1|2 test&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 4 | test1 | 123 | 0 || 7 | 1 | 1 | 1 |+-----+----------+----------+-------+2 rows in set (0.00 sec) 匹配范围:如[1-3],[a-z]; 123456789mysql&gt; SELECT uid,username,password,state FROM user WHERE username REGEXP &quot;test[1-3]&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 4 | test1 | 123 | 0 || 5 | test2 | 123 | 0 || 6 | test3 | 123 | 1 |+-----+----------+----------+-------+3 rows in set (0.00 sec) 匹配特殊字符： 使用 “\\\\特殊字符”，即转义 \\\\.能够匹配. \\\\f换页 \\\\n换行 \\\\r回车 \\\\t制表 \\\\纵向制表 注意： a)为了匹配 \\ 本身，需要使用 \\\\\\ b)在一般情况下正则表达式的转义加一个“\\”就可以了，在MySQL中需要加两个。 匹配字符类：[:alnum:]=[a-zA-Z0-9] [:alpha:]=[a-zA-Z] [:digit:]=[0-9] [:lower:]=[a-z] [:upper:]=[A-Z] [:xdigit:]=[a-fA-F0-9] 重复次数匹配将其加在之后：元字符 说明 * 0个或多个匹配 + 1个或多个匹配（等于{1，}） ？ 0个或1个匹配（等于{0，1}） {n} 指定数目匹配 {n,} 不少于指定数目匹配 {n,m} 匹配数目的范围 匹配任意三个连续数字： 问：把其[ [ ] ]是一种更好习惯？还是有什么区别 答：所以这里的区别是[[:digit:]],[:digit:]有的 1234567891011121314151617181920212223242526mysql&gt; SELECT uid,username,password,state FROM user WHERE password REGEXP &quot;[[:digit:]]{3}&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 4 | test1 | 123 | 0 || 3 | fly | 123 | 0 || 5 | test2 | 123 | 0 || 6 | test3 | 123 | 1 || 8 | dfdg | d124 | NULL || 9 | dgdg | 123r | NULL |+-----+----------+----------+-------+6 rows in set (0.00 sec)mysql&gt; SELECT uid,username,password,state FROM user WHERE password REGEXP &quot;[:digit:]{3}&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 4 | test1 | 123 | 0 || 3 | fly | 123 | 0 || 5 | test2 | 123 | 0 || 6 | test3 | 123 | 1 || 8 | dfdg | d124 | NULL || 9 | dgdg | 123r | NULL |+-----+----------+----------+-------+6 rows in set (0.00 sec) 定位元字符：元字符 说明 ^ 文本的开始 $ 文本的结尾 [[:&lt;:]] 词的开始 [[:&gt;:]] 词的结尾 示例:找出密码中以数字开头的记录：12345678910111213141516171819202122232425mysql&gt; SELECT uid,username,password,state FROM user WHERE password REGEXP &quot;^[[:digit:]\\\\.]&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 4 | test1 | 123 | 0 || 3 | fly | 123 | 0 || 5 | test2 | 123 | 0 || 6 | test3 | 123 | 1 || 7 | 1 | 1 | 1 || 9 | dgdg | 123r | NULL || 10 | gdg | 1d23 | NULL || 11 | dgdgh | 1.23s | NULL || 12 | dgklds | 2.31t | NULL |+-----+----------+----------+-------+9 rows in set (0.00 sec)// 注意区别mysql&gt; SELECT uid,username,password,state FROM user WHERE password REGEXP &quot;^[:digit:]\\\\.&quot;;+-----+----------+----------+-------+| uid | username | password | state |+-----+----------+----------+-------+| 11 | dgdgh | 1.23s | NULL || 12 | dgklds | 2.31t | NULL |+-----+----------+----------+-------+2 rows in set (0.00 sec) 创建计算字段Concat（）函数拼接字段 Concat（）拼接串，把多个串连接起来形成一个较长的串。各串之间用“，”分隔。 注:多数DBMS使用+或||来实现拼接,而mysql使用Concat（）函数 将用户名按用户名（用户id）拼接出来：12345678910mysql&gt; SELECT Concat(username,'(',uid,')') FROM user ORDER BY uid DESC LIMIT 4;+------------------------------+| Concat(username,'(',uid,')') |+------------------------------+| test6(24) || test5(23) || test4(22) || kgdlksgj(21) |+------------------------------+4 rows in set (0.00 sec) RTrim( )函数：删除值右边的所有空格12345678910mysql&gt; SELECT Concat(Rtrim(username),'(',uid,')') FROM user ORDER BY uid DESC LIMIT 4;+-------------------------------------+| Concat(Rtrim(username),'(',uid,')') |+-------------------------------------+| test6(24) || test5(23) || test4(22) || kgdlksgj(21) |+-------------------------------------+4 rows in set (0.00 sec) LTrim( )函数去掉串左边的空格，Trim( )函数去掉串两边的空格； 使用别名： 别名（alias）用AS关键字赋予，使用别名能让客户机更好的使用数据，别名有时也叫导出列； 123456789101112mysql&gt; SELECT Concat(username,'(',uid,')') -&gt; AS uinfo -&gt; FROM user LIMIT 4;+----------+| uinfo |+----------+| test1(4) || fly(3) || test2(5) || test3(6) |+----------+4 rows in set (0.00 sec)","link":"/2021/10/11/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E7%AC%94%E8%AE%B01/"},{"title":"SQL学习笔记1","text":"一、数据库的相关概念DB：数据库（database）：存储数据的“仓库”。它保存了一系列有组织的数据。 DBMS： 数据库管理系统（Database Management System）。数据库是通过DBMS创建和操作的容器 SQL：结构化查询语言（Structure Query Language） 数据库存储数据的特点 1、将数据放到表中，表再放到库中 2、一个数据库中可以有多个表，每个表都有一个的名字，用来标识自己。表名具有唯一性。 3、表具有一些特性，这些特性定义了数据在表中如何存储，类似java中 “类”的设计。 4、表由列组成，我们也称为字段。所有表都是由一个或多个列组成的，每一列类似java 中的”属性”。 5、表中的数据是按行存储的，每一行类似于java中的“对象”。 SQL语言的分类DQL（Data Query Language）：数据查询语言，用于检索数据库中的数据，主要是SELECT语句； DML（Data Manipulation Language)：数据操纵语言，用于改变数据库中的数据，主要包括INSERT、UPDATE和DELETE语句； DDL（Data Definition Language)：数据定义语言，用于库和表的创建、修改、删除。主要包括CREATE、DROP、ALTER语句； DCL（Data Control Language)：数据控制语言，用于定义用户的访问权限和安全级别。主要包括GRANT和REVOKE语句； TCL（Transaction Control Language)：事务控制语言，用于维护数据的一致性，包括COMMIT、ROLLBACK和SAVEPOINT语句。 二、DQL语言1、基础查询语法：select 查询列表 from 表名; 特点： 查询列表可以是：表中的字段、常量值、表达式、函数 查询的结果可以是一个虚拟表格; 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081USE myemployees;#1.查询表中的单个字段SELECT last_name FROM employees;#2.查询表中多个字段SELECT last_name,salary,email FROM employees;#3.查询表中的所有字段SELECT * FROM employees;#4.查询常量# select 常量值;# 注意：字符型和日期型的常量值必须用单引号引起来，数值型不需要SELECT 100;SELECT 'join';#5.查询函数#select 函数名(实参列表);SELECT VERSION();#6.查询表达式 SELECT 100%98;#7.起别名/*1.便于理解2.如果要查询的字段有重名的情况,使用别名区分*/#方式一:使用ASSELECT 100%98 AS 结果;SELECT last_name AS 姓,first_name AS 名 FROM employees;#方式二:使用空格SELECT last_name 姓,first_name 名 FROM employees;#案例:查询salary,结果显示 out putSELECT salary AS &quot;out put&quot; FROM employees;#8.去重# select distinct 字段名 from 表名;#案例:查询员工表中涉及的所有部门编号SELECT DISTINCT department_id FROM employees;#9.+号的作用#案例:查询员工的名和姓,并显示为姓名/*java中的+号:1.运算符:两个操作数都为数据型2.连接符:只要有一个操作数为字符串mysql中的+号:只能作为运算符select 100+90; 两个操作数都为数值型,做加法运算select '123+90';其中一方为字符型,试图将字符型数值转换为数值型 如果转换成功,则继续做加法运算select 'john'+90; 如果转换失败,则将字符型数值转换成0select null+0; 只要其中一方为null,则结果肯定为null.*/SELECT last_name+first_name AS 姓名 FROM employees; #10.【补充】concat函数 /*功能：拼接字符select concat(字符1，字符2，字符3,...);*/SELECT CONCAT('a','b','c') AS 结果 FROM employees;SELECT CONCAT(last_name,first_name) AS 姓名 FROM employees;#11.【补充】ifnull函数#功能：判断某字段或表达式是否为null，如果为null 返回指定的值，否则返回原本的值SELECT IFNULL(commission_pct,0) FROM employees;#12.【补充】isnull函数#功能：判断某字段或表达式是否为null，如果是，则返回1，否则返回0 2、条件查询语法：select 查询列表 from 表名 where 筛选条件; 特点：模糊查询 like: 一般搭配通配符使用，可以判断字符型或数值型 通配符：%任意多个字符，_任意单个字符 like、between anWd、in、is null 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#一.按条件表达式筛选#案例1:查询工资&gt;12000的员工信息SELECT * FROM employees WHERE salary&gt;12000;#案例2:查询部门编号不等于90号的员工名和部门编号SELECT last_name,department_id FROM employees WHERE department_id &lt;&gt; 90;#二、按逻辑表达式筛选#案例1:查询工资z在10000到20000之间的员工名、工资及奖金SELECT last_name,salary,commission_pct FROM employees WHERE salary&gt;=10000 AND salary&lt;=20000;#案例2:查询部门编号不是在90-110之间,或者工资高于15000的员工信息SELECT * FROM employees WHERE department_id &lt;90 OR department_id&gt;110 OR salary&gt;15000;#三、模糊查询#1.like#案例1:查询员工名中包含字符a的员工信息SELECT * FROM employees WHERE last_name LIKE '%a%';#案例2:查询员工名中第三个字符为b，第五个字符为a的员工名和工资SELECT last_name,salary FROM employees WHERE last_name LIKE '__b_a%';#案例3:查询员工名种第二个字符为_的员工名SELECT last_name FROM employees WHERE last_name LIKE '_\\_%';#2.between and#案例1:查询员工编号在100到120之间的员工信息SELECT * FROM employees WHERE employee_id&gt;=100 AND employee_id&lt;=120;SELECT * FROM employees WHERE employee_id BETWEEN 100 AND 120;/*注意事项：1.提高语句简洁度2.包含临界值3.两个临界值不能调换顺序*/#3.in/*含义:判断某字段的值是否属于in列表中的某一项特点: 1.使用in提高语句简洁度 2.in列表的值类型必须一致或兼容*/#案例1:查询员工的工种编号是IT_PROG、AD_VP、AD_PRES中的一个员工名和工种编号SELECT last_name,job_id FROM employees WHERE job_id='IT_PROG' OR job_id='AD_PRES' OR job_id='AD_VP';SELECT last_name,job_id FROM employees WHERE job_id IN('IT_PROG','AD_PRES','AD_VP');#4.is null/*=或&lt;&gt;不能用于判断null值is null 或 is not null 可以判断null值*/#案例1:查询没有奖金的员工名和奖金率SELECT last_name,commission_pct FROM employees WHERE commission_pct IS NULL;SELECT last_name,commission_pct FROM employees WHERE commission_pct IS NOT NULL;#安全等于&lt;=&gt;#案例1:查询没有奖金的员工名和奖金率SELECT last_name,commission_pct FROM employees WHERE commission_pct &lt;=&gt; NULL;#案例2:查询工资为12000的员工信息SELECT last_name,commission_pct FROM employees WHERE salary &lt;=&gt; 12000;#is null PK &lt;=&gt;# 普通类型的数值 null值 可读性# is null × √ √# &lt;=&gt; √ √ × 3、排序查询引入：select * from employees; 语法：select 查询列表 from 表 【where 筛选条件】 order by 特点： asc代表的是升序，desc代表降序，不写默认为升序 order by子句中可以支持单个字段、多个字段、表达式、函数、别名 order by子句一般是放在查询语句的最后面,limit子句除外 示例： 123456789101112131415161718192021222324#案例1:查询员工信息,要求工资从高到低排序SELECT * FROM employees ORDER BY salary DESC;SELECT * FROM employees ORDER BY salary;#案例2:查询部门编号是&gt;=90，按入职时间的先后进行排序SELECT * FROM employees WHERE department_id&gt;=90 ORDER BY hiredate ASC;#案例3:按年薪的高低显示员工的信息和年薪【按表达式排序】SELECT *,salary*12*(1+IFNULL(commission_pct,0)) 年薪 FROM employees ORDER BY salary*12*(1+IFNULL(commission_pct,0)) DESC; #案例4:按年薪的高低显示员工的信息和年薪【按别名排序】SELECT *,salary*12*(1+IFNULL(commission_pct,0)) 年薪 FROM employees ORDER BY salary*12*(1+IFNULL(commission_pct,0)) 年薪 DESC;#案例5:按姓名的长度显示员工的姓名和工资【按函数排序】SELECT LENGTH(last_name) 字节长度,last_name,salaryFROM employeesORDER BY LENGTH(last_name) DESC;#案例6:查询员工共信息,要求按工资排序，再按员工编号排序【按多个字段排序】SELECT * FROM employeesORDER BY salary ASC,employee_id DESC; 4、常见函数概念：类似于Java的方法，将一组逻辑语句封装在方法体中，对外暴露方法名 优点：1.隐藏了实现细节 2.提高了代码的重用性 语法：select 函数名(实参列表) 【from 表】; 特点： 1.叫什么(函数名) 2.干什么(函数功能) 示例: 1.单行函数，如concat、length、ifnull等; 2.分组函数，做统计使用 5、单行函数单行函数分类：字符函数、数学函数、日期函数、其他函数、流程控制函数 字符函数具体案例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201#一.字符函数#1.length 获取参数值的字节值SELECT LENGTH('subei');SELECT LENGTH('鬼谷子qwe');SHOW VARIABLES LIKE '%char%';#2.concat 拼接字符串SELECT CONCAT(last_name,'_',first_name) 姓名 FROM employees;#3.upper:变大写、lower：变小写SELECT UPPER('ton');SELECT LOWER('ton');#示例：将姓变大写，名变小写，然后拼接SELECT CONCAT(UPPER(last_name),LOWER(first_name)) 姓名 FROM employees;#4.substr、substring#注意:索引从1开始#截取从指定所有处后面的所以字符SELECT SUBSTR('吴刚伐桂在天上',4) out_put;#截取从指定索引处指定字符长度的字符SELECT SUBSTR('吴刚伐桂在天上',1,2) out_put;#案例:姓名中首字符大写,其他字符小写，然后用_拼接,显示出来SELECT CONCAT(UPPER(SUBSTR(last_name,1,1)),'_',LOWER(SUBSTR(last_name,2))) out_put FROM employees;#5.instr:获取子串第一次出现的索引,找不到返回0SELECT INSTR('MySQL技术进阶','技术') AS out_put;#6.trim:去前后空格SELECT LENGTH(TRIM(' 霍山 ')) AS out_put;SELECT TRIM('+' FROM '++++李刚+++刘邦+++') AS out_put;#7.lpad:用指定的字符实现左填充指定长度SELECT LPAD('梅林',8,'+') AS out_put;#8.rpad:用指定的字符实现右填充指定长度SELECT RPAD('梅林',5,'&amp;') AS out_put;#9.replace:替换SELECT REPLACE('莉莉伊万斯的青梅竹马是詹姆','詹姆','斯内普') AS out_put;二、数学函数#1.round:四舍五入SELECT ROUND(1.45);SELECT ROUND(1.567,2);#2.ceil:向上取整,返回&gt;=该参数的最小整数SELECT CEIL(1.005);SELECT CEIL(-1.002);#3.floor:向下取整,返回&lt;=该参数的最大整数SELECT FLOOR(-9.99);#4.truncate:截断SELECT TRUNCATE(1.65,1);#5.mod:取余SELECT MOD(10,3);#6.rand:获取随机数，返回0-1之间的小数SELECT RAND();三、日期函数#1.now:返回当前系统时间+日期SELECT NOW();#2.year:返回年SELECT YEAR(NOW());SELECT YEAR(hiredate) 年 FROM employees;#3.month:返回月#MONTHNAME:以英文形式返回月SELECT MONTH(NOW());SELECT MONTHNAME(NOW());#4.day:返回日#DATEDIFF:返回两个日期相差的天数SELECT DAY(NOW());SELECT DATEDIFF('2020/06/30','2020/06/21');#5.str_to_date:将字符通过指定格式转换成日期SELECT STR_TO_DATE('2020-5-13','%Y-%c-%d') AS out_put;#6.date_format:将日期转换成字符SELECT DATE_FORMAT('2020/6/6','%Y年%m月%d日') AS out_put;SELECT DATE_FORMAT(NOW(),'%Y年%m月%d日') AS out_put;#7.curdate:返回当前日期SELECT CURDATE();#8.curtime:返回当前时间SELECT CURTIME();四、其他#version 当前数据库服务器的版本SELECT VERSION();#database 当前打开的数据库SELECT DATABASE();#user当前用户SELECT USER();#password('字符')：返回该字符的密码形式SELECT PASSWORD('a');#md5('字符'):返回该字符的md5加密形式SELECT MD5('a');五、流程函数#1.if函数: if else效果SELECT IF(10&lt;5,'大','小');SELECT last_name,commission_pct,IF(commission_pct IS NULL,'没奖金！！！','有奖金!!!') 备注 FROM employees;#2.case函数#使用一:switch case 的效果/*java中switch(变量或表达式){ case 常量1:语句1;break; ... default:语句n;break;}mysql中case 要判断的变量或表达式when 常量1 then 要显示的值1或语句1when 常量2 then 要显示的值2或语句2...else 要显示的值n或语句nend#案例:查询员工的工资,要求:部门号=30,显示的工资为1.1倍部门号=40,显示的工资为1.2倍部门号=50,显示的工资为1.3倍其他部门,显示的工资为原工资*/SELECT salary 原始工资,department_id,CASE department_idWHEN 30 THEN salary*1.1WHEN 40 THEN salary*1.2WHEN 50 THEN salary*1.3ELSE salaryEND AS 新工资FROM employees;#3.case函数的使用二:类似于多重if/*java中:if(条件1){ 语句1;}else if(条件2){ 语句2;}...else{ 语句n;} mysql中:case when 条件1 then 要显示的值1或语句1when 条件2 then 要显示的值2或语句2...else 要显示的值n或语句nend*/#案例:查询员工的工资的情况/*如果工资&gt;20000，显示A级别如果工资&gt;15000，显示B级别如果工资&gt;10000，显示c级别否则，显示D级别*/SELECT salary,CASEWHEN salary&gt;20000 THEN 'A'WHEN salary&gt;15000 THEN 'B'WHEN salary&gt;10000 THEN 'C'ELSE 'D'END AS 工资等级FROM employees; 6、分组函数功能：用作统计使用，又称为聚合函数或统计函数或组函数 分类：sum 求和、avg 平均值、max 最大值、min最小值count 计算个数 特点: 1.sum和avg一般用于处理数值型max、min、count可以处理任何数据类型 2.以上分组函数都忽略null 3.都可以搭配distinct使用，实现去重的统计select sum(distinct 字段) from 表; 4.count函数count(字段)：统计该字段非空值的个数count(*):统计结果集的行数 5.和分组函数一同查询的字段，要求是group by后出现的字段 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#1.简单使用SELECT SUM(salary) FROM employees;SELECT AVG(salary) FROM employees;SELECT MAX(salary) FROM employees;SELECT MIN(salary) FROM employees;SELECT COUNT(salary) FROM employees;SELECT SUM(salary) 和,ROUND(AVG(salary),2) 平均,MAX(salary) 最高,MIN(salary) 最低,COUNT(salary) 个数FROM employees;#2.参数支持哪些数据类型SELECT SUM(last_name),AVG(last_name) FROM employees;SELECT SUM(hiredate),AVG(hiredate) FROM employees;SELECT MAX(last_name),MIN(last_name) FROM employees;SELECT MAX(hiredate),MIN(hiredate) FROM employees;SELECT COUNT(commission_pct) FROM employees;SELECT COUNT(last_name) FROM employees;#3.是否忽略nullSELECT SUM(commission_pct),AVG(commission_pct) FROM employees;SELECT commission_pct FROM employees;SELECT SUM(commission_pct),AVG(commission_pct),SUM(commission_pct)/35,AVG(commission_pct)/107 FROM employees;SELECT MAX(commission_pct),MIN(commission_pct) FROM employees;SELECT COUNT(commission_pct) FROM employees;#4.和distinct搭配SELECT SUM(DISTINCT salary),SUM(salary) FROM employees;SELECT COUNT(DISTINCT salary),COUNT(salary) FROM employees;#5.count函数详解SELECT COUNT(salary) FROM employees;SELECT COUNT(*) FROM employees;SELECT COUNT(1) FROM employees;/*效率上：MyISAM存储引擎，count(*)最高InnoDB存储引擎，count(*)和count(1)效率&gt;count(字段)*/#6.和分组函数一同查询的字段有限制SELECT AVG(salary),employee_id FROM employees; 7、分组查询语法: 123456select 分组函数,分组后的字段from 表【where 筛选条件】group by 分组的字段【having 分组后的筛选】【order by 排序列表】 注意:查询列表必须特殊,要求是分组函数和group by后出现的字段 特点: 1.分组查询中的筛选条件分为两类 123456 使用关键字 筛选的表 位置分组前筛选 where 原始表 group by的前面分组后筛选 having 分组后的结果 group by的后面1.分组函数做条件肯定是放在having子句中2.能用分组前筛选的，就优先考虑使用分组前筛选 2.group by子句支持单个字段分组，多个字段分组(多个字段之间用逗号隔开没有顺序要求),表达式或函数(使用较少) 3.也可以添加排序(排序放在整个分组查询的最后) 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#引入:查询每个部门的平均工资SELECT AVG(salary) FROM employees;#案例1:查询每个工种的最高工资SELECT MAX(salary),job_id FROM employees GROUP BY job_id;#案例2:查询每个位置上的部门个数SELECT COUNT(*),location_idFROM departmentsGROUP BY location_id;#添加筛选条件#案例1:查询邮箱中包含a字符的，每个部门的平均工资SELECT AVG(salary),department_id FROM employeesWHERE email LIKE '%a%' GROUP BY department_id;#案例2:查询有奖金的每个领导手下员工的最高工资SELECT MAX(salary),manager_id FROM employeesWHERE commission_pct IS NOT NULLGROUP BY manager_id;#添加复杂的筛选条件#案例1:查询哪个部门的员工个数&gt;2#1.查询每个部门的员工个数SELECT COUNT(*),department_id FROM employeesGROUP BY department_id;#2.根据1的结果进行筛选，查询哪个部门的员工个数大于2SELECT COUNT(*),department_id FROM employeesGROUP BY department_id HAVING COUNT(*)&gt;2;#案例2:查询每个工种有奖金的员工的最高工资&gt;12000的工种编号和最高工资 #1.查询每个工种有奖金的员工的最高工资 SELECT MAX(salary),job_id FROM employees WHERE commission_pct IS NOT NULL GROUP BY job_id; #2.根据结果继续筛选，最高工资&gt;12000 SELECT MAX(salary), job_id FROM employees WHERE commission_pct IS NOT NULL GROUP BY job_id HAVING MAX(salary)&gt;12000; #按表达式或函数分组#案例:按员工姓名的长度分组,查询每一组的员工个数,筛选员工个数&gt;5#1.查询每个长度的员工个数 SELECT COUNT(*),LENGTH(last_name) len_name FROM employees GROUP BY LENGTH(last_name); #2.添加筛选条件SELECT COUNT(*) c,LENGTH(last_name) len_name FROM employees GROUP BY len_name HAVING c&gt;5;#按多个字段查询#案例:查询每个部门每个工种的员工的平均工资SELECT AVG(salary),department_id,job_idFROM employees GROUP BY department_id,job_id;#添加排序#案例:查询每个部门每个工种的员工的平均工资,按平均工资的高低查询SELECT AVG(salary),department_id,job_idFROM employees GROUP BY department_id,job_idORDER BY AVG(salary) DESC;","link":"/2021/10/11/sql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"},{"title":"输入网址之后的种种","text":"在学习了部分网络知识后，我们可以大致的想象到在键入网址后，到网页显示出对应内容，其间发生了什么 接下来以简单的网络拓扑模型作为例子，探究一个数据包在网络中发生的种种。 HTTP浏览器做的第一步工作是解析 URL 首先浏览器做的第一步工作就是要对 URL 进行解析，从而生发送给 Web 服务器的请求信息。 让我们看看一条长长的 URL 里的各个元素的代表什么，见下图： 所以图中的长长的 URL 实际上是请求服务器里的文件资源。 要是上图中的蓝色部分 URL 元素都省略了，哪应该是请求哪个文件呢？ 当没有路径名时，就代表访问根目录下事先设置的默认文件，也就是 /index.html 或者 /default.html 这些文件，这样就不会发生混乱了。 生产 HTTP 请求信息对 URL 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。 真实地址查询 —— DNS通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。 但在发送之前，还有一项工作需要完成，那就是查询服务器域名对于的 IP 地址，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。 比如我们打电话的时候，必须要知道对方的电话号码，但由于电话号码难以记忆，所以通常我们会将对方电话号 + 姓名保存在通讯录里。 所以，有一种服务器就专门保存了 Web 服务器域名与 IP 的对应关系，它就是 DNS 服务器。 域名的层级关系DNS 中的域名都是用句点来分隔的，比如 www.server.com，这里的句点代表了不同层次之间的界限。 在域名中，越靠右的位置表示其层级越高。 毕竟域名是外国人发明，所以思维和中国人相反，比如说一个城市地点的时候，外国喜欢从小到大的方式顺序说起（如 XX 街道 XX 区 XX 市 XX 省），而中国则喜欢从大到小的顺序（如 XX 省 XX 市 XX 区 XX 街道）。 根域是在最顶层，它的下一层就是 com 顶级域，再下面是 server.com。 所以域名的层级关系类似一个树状结构： 根 DNS 服务器 顶级域 DNS 服务器（com） 权威 DNS 服务器（server.com） 根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。 这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。 因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。 域名解析的工作流程 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。” 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？” 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。 至此，我们完成了 DNS 的解析过程。现在总结一下，整个过程我画成了一个图。 协议栈通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈。 协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。 应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，它们两会接受应用层的委托执行收发数据的操作。 协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据刽被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。 此外 IP 中还包括 ICMP 协议和 ARP 协议。 ICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。 ARP 用于根据 IP 地址查询相应的以太网 MAC 地址。 IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。 可靠传输 —— TCPHTTP 是基于 TCP 协议传输的，所以在这我们先了解下 TCP 协议。 TCP 包头格式我们先看看 TCP 报文头部的格式： 首先，源端口号和目标端口号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。 接下来有包的序号，这个是为了解决包乱序的问题。 还有应该有的是确认号，目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决不丢包的问题。 接下来还有一些状态位。例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。 还有一个重要的就是窗口大小。TCP 要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。 除了做流量控制以外，TCP还会做拥塞控制，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。不能改变世界，就改变自己嘛。 TCP 传输数据之前，要先三次握手建立连接在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为三次握手。 这个所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。 然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。 服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。 客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。 服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。 所以三次握手目的是保证双方都有发送和接收的能力。 如何查看 TCP 的连接状态？TCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。 TCP 分割数据如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解一块块的数据发送，而不是一次性发送所有数据。 MTU：一个网络包的最大长度，以太网中一般为 1500 字节。 MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。 数据会被以 MSS 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。 TCP 报文生成TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 80， HTTPS 默认端口号是 443）。 在双方建立了连接后，TCP 报文中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报文之后，就需交给下面的网络层处理。 至此，网络包的报文如下图: 远程定位 —— IPTCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成网络包发送给通信对象。 IP 包头格式我们先看看 IP 报文头部的格式： 在 IP 协议里面需要有源地址 IP 和 目标地址 IP： 源地址IP，即是客户端输出的 IP 地址； 目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。 因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06（十六进制），表示协议为 TCP。 假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？当存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪个一块网卡来发送包。 这个时候就需要根据路由表规则，来判断哪一个网卡作为源地址 IP。 在 Linux 操作系统，我们可以使用 route -n 命令查看当前系统的路由表。 举个例子，根据上面的路由表，我们假设 Web 服务器的目标地址是 192.168.10.200。 首先先和第一条条目的子网掩码（Genmask）进行 与运算，得到结果为 192.168.10.0，但是第一个条目的 Destination 是 192.168.3.0，两者不一致所以匹配失败。 再与第二条目的子网掩码进行 与运算，得到的结果为 192.168.10.0，与第二条目的 Destination 192.168.10.0 匹配成功，所以将使用 eth1 网卡的 IP 地址作为 IP 包头的源地址。 那么假设 Web 服务器的目标地址是 10.100.20.100，那么依然依照上面的路由表规则判断，判断后的结果是和第三条目匹配。 第三条目比较特殊，它目标地址和子网掩码都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。 IP 报文生成至此，网络包的报文如下图: 两点传输 —— MAC生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部。 MAC 包头格式MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。 在 MAC 包头里需要发送方 MAC 地址和接收方目标 MAC 地址，用于两点之间的传输。 一般在 TCP/IP 通信里，MAC 包头的协议类型只使用： 0800 ：IP 协议 0806 ：ARP 协议 MAC 发送方和接收方如何确认?发送方的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。 接收方的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。 所以先得搞清楚应该把包发给谁，这个只要查一下路由表就知道了。在路由表中找到相匹配的条目，然后把包发给 Gateway 列中的 IP 地址就可以了。 既然知道要发给谁，按如何获取对方的 MAC 地址呢？不知道对方 MAC 地址？不知道就喊呗。 此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。 ARP 协议会在以太网中以广播的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。 然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。 如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。 每次都要广播获取，这不是很麻烦吗？放心，在后续操作系统会把本次查询结果放到一块叫做 ARP 缓存的内存空间留着以后用，不过缓存的时间就几分钟。 也就是说，在发包时： 先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。 而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。 查看 ARP 缓存内容在 Linux 系统中，我们可以使用 arp -a 命令来查看 ARP 缓存的内容。 MAC 报文生成至此，网络包的报文如下图: 出口 —— 网卡IP 生成的网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。 负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。 网卡驱动从 IP 模块获取到包之后，会将其复制到网卡内的缓存区中，接着会其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。 起始帧分界符是一个用来表示包起始位置的标记 末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏 最后网卡会将包转为电信号，通过网线发送出去。 送别者 —— 交换机下面来看一下包是如何通过交换机的。交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。 交换机的包接收操作首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。 然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。 计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有 MAC 地址。 将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。 交换机的 MAC 地址表主要包含两个信息： 一个是设备的 MAC 地址， 另一个是该设备连接在交换机的哪个端口上。 举个例子，如果收到的包的接收方 MAC 地址为 00-02-B3-1C-9C-F9，则与图中表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 3 号端口上，然后就可以通过交换电路将包发送到相应的端口了。 所以，交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。 当 MAC 地址表找不到指定的 MAC 地址会怎么样？地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。 这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。 这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。 有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？” 其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。 局域网中每秒可以传输上千个包，多出一两个包并无大碍。 此外，如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。 以下两个属于广播地址： MAC 地址中的 FF:FF:FF:FF:FF:FF IP 地址中的 255.255.255.255 出境大门 —— 路由器 路由器与交换机的区别网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。 这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。 不过在具体的操作过程上，路由器和交换机是有区别的。 因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址； 而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。 路由器基本原理路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。 当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。 路由器的包接收操作首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。 如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。 总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。 查询路由表确定输出端口完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。 MAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。 接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。 转发操作分为几个阶段，首先是查询路由表判断转发目标。 具体的工作流程根据上图，举个例子。 假设地址为 10.10.1.101 的计算机要向地址为 192.168.1.100 的服务器发送一个包，这个包先到达图中的路由器。 判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。 路由匹配和前面讲的一样，每个条目的子网掩码和 192.168.1.100 IP 做 &amp; 与运算后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。 如第二条目的子网掩码 255.255.255.0 与 192.168.1.100 IP 做 &amp; 与运算后，得到结果是 192.168.1.0 ，这与第二条目的目标地址 192.168.1.0 匹配，该第二条目记录就会被作为转发目标。 实在找不到匹配路由时，就会选择默认路由，路由表中子网掩码为 0.0.0.0 的记录表示「默认路由」。 路由器的发送操作接下来就会进入包的发送操作。 首先，我们需要根据路由表的网关列判断对方的地址。 如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。 知道对方的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。 路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。 接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 0080 （十六进制）表示 IP 协议。 网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。 发送出去的网络包会通过交换机到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。 接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。 不知你发现了没有，在网络包传输的过程中，源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址，因为需要 MAC 地址在以太网内进行两个设备之间的包传输。 互相扒皮 —— 服务器 与 客户端数据包抵达了服务器，服务器肯定高兴呀，正所谓有朋自远方来，不亦乐乎？ 服务器高兴的不得了，于是开始扒数据包的皮！就好像你收到快递，能不兴奋吗？ 数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。 接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。 于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。 于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。 服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。 HTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。 穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。 最后跳到了客户端的城门把手的路由器，路由器扒开 IP 头部发现是要找城内的人，于是把包发给了城内的交换机，再由交换机转发到客户端。 客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！ 于是，客户端开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！ 最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。","link":"/2021/08/13/%E8%BE%93%E5%85%A5%E7%BD%91%E5%9D%80%E4%B9%8B%E5%90%8E%E5%8F%91%E7%94%9F%E7%9A%84%E7%A7%8D%E7%A7%8D/"},{"title":"JVM-垃圾回收","text":"常见面试题 如何判断对象是否死亡（两种方法）。 简单的介绍一下强引用、软引用、弱引用、虚引用（虚引用与软引用和弱引用的区别、使用软引用能带来的好处）。 如何判断一个常量是废弃常量 如何判断一个类是无用的类 垃圾收集有哪些算法，各自的特点？ HotSpot 为什么要分为新生代和老年代？ 常见的垃圾回收器有哪些？ 介绍一下 CMS,G1 收集器。 Minor Gc 和 Full GC 有什么不同呢？ JVM 内存分配与回收Java 的自动内存管理主要是针对对象内存的回收和对象内存的分配。同时，Java 自动内存管理最核心的功能是 堆 内存中对象的分配与回收。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 堆空间的基本结构： 大部分情况，对象都会首先在 Eden 区域分配 123456// 在一次`新生代垃圾回收`后，如果对象还`存活`，则会进入 `s0 或者 s1`，并且对象的`年龄还会加 1`(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为大于 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置默认值，这个值会在虚拟机运行过程中进行调整，可以通过-XX:+PrintTenuringDistribution 来打印出当次 GC 后的 Threshold。 Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的一半时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值 经过这次 GC 后，Eden 区和”From”区已经被清空。这个时候，”From”和”To”会交换他们的角色，也就是新的”To”就是上次 GC 前的“From”，新的”From”就是上次 GC 前的”To”。不管怎样，都会保证名为 To 的 Survivor 区域是空的。Minor GC 会一直重复这样的过程，在这个过程中，有可能当次 Minor GC 后，Survivor 的”From”区域空间不够用，有一些还达不到进入老年代条件的实例放不下，则放不下的部分会提前进入老年代。 1.1 对象优先在 eden 区分配目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC","link":"/2022/02/02/JVM-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"title":"JVM-内存","text":"常见面试题 ： 介绍下 Java 内存区域（运行时数据区） Java 对象的创建过程（五步，建议能默写出来并且要知道每一步虚拟机做了什么） 对象的访问定位的两种方式（句柄和直接指针两种方式） 内存区域详解运行时数据区域线程私有的： 程序计数器 程序计数器是一块较小的内存空间，当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。 程序计数器主要有两个作用： (1)字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 (2)在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 注意 ：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期和线程相同 虚拟机栈 生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。 Java 内存可以粗糙的区分为:堆内存（Heap）、栈内存 (Stack)栈也就是 Java 虚拟机栈，由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。 局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。 Java 虚拟机栈会出现 **两种错误**： StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： Java 虚拟机栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 注： 方法/函数如何调用？ Java 栈可以类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入 Java 栈，每一个函数调用结束后，都会有一个栈帧被弹出。 Java 方法有两种返回方式：(不管哪种返回方式都会导致栈帧被弹出。) (1)return 语句。 (2)抛出异常。 本地方法栈 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。 线程共享的： 堆 Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称作 GC 堆（Garbage Collected Heap）。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代；进一步划分的目的是更好地回收内存，或者更快地分配内存。 前期，堆内存被通常分为下面三部分： 新生代内存(Young Generation) 老生代(Old Generation) 元空间(Metaspace) [JDK 8 版本之后 PermGen 已被 Metaspace(元空间) 取代,元空间使用的是直接内存。] 堆这里最容易出现的就是 OutOfMemoryError 错误，并且出现这种错误之后的表现形式还会有几种，比如： java.lang.OutOfMemoryError: GC Overhead Limit Exceeded ： 当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。 java.lang.OutOfMemoryError: Java heap space :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发此错误。(和配置的最大堆内存有关，且受制于物理内存大小。 方法区 与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义 为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢?(1)整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。 当元空间溢出时会得到如下错误： java.lang.OutOfMemoryError: MetaSpace 你可以使用 -XX：MaxMetaspaceSize 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。-XX：MetaspaceSize 调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。 (2)元空间里面存放的是类的元数据，这样加载多少类的元数据就不由 MaxPermSize 控制了, 而由系统的实际可用空间来控制，这样能加载的类就更多了。 (3)在 JDK8，合并 HotSpot 和 JRockit 的代码时, JRockit 从来没有一个叫永久代的东西, 合并之后就没有必要额外的设置这么一个永久代的地方了。 运行时常量池运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用） 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。 JDK1.8 hotspot 移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace) 直接内存 (非运行时数据区的一部分) 直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。 JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。 本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。 对象的创建Step1:类加载检查虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 Step2:分配内存在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 内存分配的两种方式 （补充内容，需要掌握）：指针碰撞 ： 适用场合 ：堆内存规整（即没有内存碎片）的情况下。 原理 ：过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。 使用该分配方式的 GC 收集器：Serial, ParNew 空闲列表 ： 适用场合 ： 堆内存不规整的情况下。 原理 ：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。 使用该分配方式的 GC 收集器：CMS 选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除“，还是”标记-整理“（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的。 内存分配并发问题（补充内容，需要掌握）在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全： CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。**虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性**。 TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配 Step3:初始化零值内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 Step4:设置对象头初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 Step5:执行 init 方法在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行&lt;init&gt;方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 对象的内存布局在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头、实例数据和对齐填充。 Hotspot 虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。 对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 对象的访问定位建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有：使用句柄、直接指针。 句柄如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 直接指针如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。 使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。","link":"/2022/02/02/JVM-%E5%86%85%E5%AD%98/"},{"title":"Spring","text":"Spring IOC &amp; AOPIOCIoC（Inverse of Control:控制反转） 是一种设计思想，而不是一个具体的技术实现。IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。不过， IoC 并非 Spring 特有，在其他语言中也有应用。 为什么叫控制反转？ 控制 ：指的是对象创建（实例化、管理）的权力 反转 ：控制权交给外部环境（Spring 框架、IoC 容器） IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。 在 Spring 中， IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象。 Spring 一般通过 XML 文件来配置 Bean。SpringBoot 注解配置。 在 Spring 中， IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象。 Spring 时代我们一般通过 XML 文件来配置 Bean，后来开发人员觉得 XML 文件来配置不太好，于是 SpringBoot 注解配置就慢慢开始流行起来。 AOPAOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理 Spring bean什么是 bean？简单来说，bean 代指的就是那些被 IoC 容器所管理的对象。 我们需要告诉 IoC 容器帮助我们管理哪些对象，这个是通过配置元数据来定义的。配置元数据可以是 XML 文件、注解或者 Java 配置类。 bean 的作用域有哪些?Spring 中 Bean 的作用域通常有下面几种： singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的，对单例设计模式的应用。 prototype : 每次请求都会创建一个新的 bean 实例。 request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。 session : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。 global-session ： 全局 session 作用域，仅仅在基于 portlet 的 web 应用中才有意义，Spring5 已经没有了。Portlet 是能够生成语义代码(例如：HTML)片段的小型 Java Web 插件。它们基于 portlet 容器，可以像 servlet 一样处理 HTTP 请求。但是，与 servlet 不同，每个 portlet 都有不同的会话。 单例 bean 的线程安全问题？单例 bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候是存在资源竞争的。 常见的有两种解决办法： 在 bean 中尽量避免定义可变的成员变量。 在类中定义一个 ThreadLocal 成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。 不过，大部分 bean 实际都是无状态（没有实例变量）的（比如 Dao、Service），这种情况下， bean 是线程安全的。 @Component 和 @Bean 的区别是什么？ @Component 注解作用于类，而@Bean注解作用于方法。 @Component通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我。 @Bean 注解比 @Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean 来实现。 将一个类声明为 bean 的注解有哪些?我们一般使用 @Autowired 注解自动装配 bean，要想把类标识成可用于 @Autowired 注解自动装配的 bean 的类,采用以下注解可实现： @Component ：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。 @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。 @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。 @Controller : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。 Spring 管理事务的方式？ 编程式事务 ： 在代码中硬编码(不推荐使用) : 通过 TransactionTemplate或者 TransactionManager 手动管理事务，实际应用中很少使用，但是对于你理解 Spring 事务管理原理有帮助。 声明式事务 ： 在 XML 配置文件中配置或者直接基于注解（推荐使用） : 实际是通过 AOP 实现（基于@Transactional 的全注解方式使用最多） 题库SpringMVC五大核心组件1.DispatcherServlet 请求入口 2.HandlerMapping 请求派发,负责请求和控制器建立一一对应的关系 3.Controller 处理器 4.ModelAndView 封装模型信息和视图信息 5.ViewResolver 视图处理器,定位页面","link":"/2022/02/02/Spring/"},{"title":"Redis","text":"RedisRedis除了做缓存之外，也经常用来做分布式锁，甚至是消息队列。 Redis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。 Redis 和 Memcached 的区别和共同点共同点 ： 都是基于内存的数据库，一般都用来当做缓存使用。 都有过期策略。 两者的性能都非常高。 区别 ： Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset(sorted set)，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。 Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中。 Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。 Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。 Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。 （Redis 6.0 引入了多线程 IO ） Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。 Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。 为什么要用 Redis (缓存)？高性能 ： 假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。那就保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。不过，要保持数据库和缓存中的数据的一致性。 如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！ 高并发： 一般像 MySQL 这类的数据库的 QPS (服务器每秒可以执行的查询次数)大概都在 1w 左右 ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高） 由此可见，直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。 布隆过滤器什么是布隆过滤器由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构，检索元素是否在给定大集合中的数据结构。它占用空间少并且效率高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。 布隆过滤器的原理介绍当一个元素加入布隆过滤器中的时候，会进行如下操作： 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为 1。 判断一个元素是否存在于布隆过滤器 对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 布隆过滤器使用场景判断给定数据是否存在：比如判断一个数字是否存在于包含大量数字的数字集中（数字集很大，5 亿以上！）、 防止缓存穿透（判断请求的数据是否有效避免直接绕过缓存请求数据库）等等、邮箱的垃圾邮件过滤、黑名单功能等等。 去重：比如爬给定网址的时候对已经爬取过的 URL 去重。","link":"/2022/02/02/Redis/"},{"title":"SpringBoot","text":"什么是 SpringBoot 自动装配？自动装配可以简单理解为：通过注解或者一些简单的配置就能在 Spring Boot 的帮助下实现某块功能。 自动装配@EnableAutoConfiguration 只是一个简单地注解，自动装配核心功能的实现实际是通过 AutoConfigurationImportSelector类。 Spring Boot 通过@EnableAutoConfiguration开启自动装配，通过 SpringFactoriesLoader实例化相应的Bean, 最终加载META-INF/spring.factories中的自动配置类实现自动装配 自动配置类其实就是通过@Conditional按需加载的配置类，想要其生效必须引入spring-boot-starter-xxx包实现起步依赖 1. @SpringBootApplication@SpringBootApplication看作是 @Configuration、@EnableAutoConfiguration、@ComponentScan 注解的集合。 这三个注解的作用分别是： @EnableAutoConfiguration：启用 SpringBoot 的自动配置机制 @Configuration：允许在上下文中注册额外的 bean 或导入其他配置类 @ComponentScan： 扫描被 @Component (@Service,@Controller)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean(在@ComponentScan后使用excludeFilters={} )。 2. Spring Bean 相关2.1. @Autowired自动导入对象到类中，被注入进的类同样要被 Spring 容器管理比如：Service 类注入到 Controller 类中。 2.2. @Component,@Repository,@Service, @Controller我们一般使用 @Autowired 注解让 Spring 容器帮我们自动装配 bean。要想把类标识成可用于 @Autowired 注解自动装配的 bean 的类,可以采用以下注解实现： @Component ：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。 @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。 @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。 @Controller : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面。 2.3. @RestController@RestController注解是 @Controller和 @ResponseBody的合集,表示这是个控制器 bean,并且是将函数的返回值直接填入 HTTP 响应体中,是 REST 风格的控制器。 单独使用 @Controller 不加 @ResponseBody的话一般是用在要返回一个视图的情况，这种情况属于比较传统的 Spring MVC 的应用，对应于前后端不分离的情况。@Controller +@ResponseBody 返回 JSON 或 XML 形式数据 2.4. @Scope声明 Spring Bean 的作用域 四种常见的 Spring Bean 的作用域： singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。 prototype : 每次请求都会创建一个新的 bean 实例。 request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。 session : 每一个 HTTP Session 会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。 2.5. @Configuration一般用来声明配置类，可以使用 @Component注解替代，不过使用@Configuration注解声明配置类更加语义化。 3. 处理常见的 HTTP 请求类型5 种常见的请求类型: GET ：请求从服务器获取特定资源。举个例子：GET /users（获取所有学生） POST ：在服务器上创建一个新的资源。举个例子：POST /users（创建学生） PUT ：更新服务器上的资源（客户端提供更新后的整个资源）。举个例子：PUT /users/12（更新编号为 12 的学生） DELETE ：从服务器删除特定的资源。举个例子：DELETE /users/12（删除编号为 12 的学生） PATCH ：更新服务器上的资源（客户端提供更改的属性，可以看做作是部分更新），使用的比较少，这里就不举例子了。 3.1. GET 请求@GetMapping(&quot;users&quot;) 等价于@RequestMapping(value=&quot;/users&quot;,method=RequestMethod.GET) 3.2. POST 请求@PostMapping(&quot;users&quot;) 等价于@RequestMapping(value=&quot;/users&quot;,method=RequestMethod.POST) 3.3. PUT 请求@PutMapping(&quot;/users/{userId}&quot;) 等价于@RequestMapping(value=&quot;/users/{userId}&quot;,method=RequestMethod.PUT) 3.4. DELETE 请求@DeleteMapping(&quot;/users/{userId}&quot;)等价于@RequestMapping(value=&quot;/users/{userId}&quot;,method=RequestMethod.DELETE) 3.5. PATCH 请求一般实际项目中，我们都是 PUT 不够用了之后才用 PATCH 请求去更新数据。 4. 前后端传值4.1. @PathVariable 和 @RequestParam@PathVariable用于获取路径参数，@RequestParam用于获取查询参数。 4.2. @RequestBody用于读取 Request 请求（可能是 POST,PUT,DELETE,GET 请求）的 body 部分并且Content-Type 为 application/json 格式的数据，接收到数据之后会自动将数据绑定到 Java 对象上去。系统会使用HttpMessageConverter或者自定义的HttpMessageConverter将请求的 body 中的 json 字符串转换为 java 对象。 一个请求方法只可以有一个@RequestBody，但是可以有多个@RequestParam和@PathVariable 5. 读取配置信息5.1. @Value(常用)使用 @Value(&quot;${property}&quot;) 读取比较简单的配置信息： 12@Value(&quot;${wuhan2020}&quot;) //配置文件中内容String wuhan2020; 5.2. @ConfigurationProperties(常用)通过@ConfigurationProperties读取配置信息并与 bean 绑定。 5.3. @PropertySource（不常用）@PropertySource读取指定 properties 文件 6. 参数校验6.1. 一些常用的字段验证的注解 @NotEmpty 被注释的字符串的不能为 null 也不能为空 @NotBlank 被注释的字符串非 null，并且必须包含一个非空白字符 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Pattern(regex=,flag=)被注释的元素必须符合指定的正则表达式 @Email 被注释的元素必须是 Email 格式。 @Min(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value)被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=)被注释的元素的大小必须在指定的范围内 @Digits(integer, fraction)被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 6.2. 验证请求体(RequestBody)在需要验证的参数上加上了@Valid注解，如果验证失败，它将抛出MethodArgumentNotValidException。 12345678910@RestController@RequestMapping(&quot;/api&quot;)public class PersonController { @PostMapping(&quot;/person&quot;) public ResponseEntity&lt;Person&gt; getPerson(@RequestBody @Valid Person person) { return ResponseEntity.ok().body(person); }} 6.3. 验证请求参数(Path Variables 和 Request Parameters)一定一定不要忘记在类上加上 @Validated 注解了，这个参数可以告诉 Spring 去校验方法参数。 12345678910@RestController@RequestMapping(&quot;/api&quot;)@Validatedpublic class PersonController { @GetMapping(&quot;/person/{id}&quot;) public ResponseEntity&lt;Integer&gt; getPersonByID(@Valid @PathVariable(&quot;id&quot;) @Max(value = 5,message = &quot;超过 id 的范围了&quot;) Integer id) { return ResponseEntity.ok().body(id); }} 7. 全局处理 Controller 层异常全局处理 Controller 层异常。 相关注解： @ControllerAdvice :注解定义全局异常处理类 @ExceptionHandler :注解声明异常处理方法 //8. JPA 9. 事务 @Transactional在要开启事务的方法上使用@Transactional注解即可 1234@Transactional(rollbackFor = Exception.class)public void save() { ......} 我们知道 Exception 分为运行时异常 RuntimeException 和非运行时异常。在@Transactional注解中如果不配置rollbackFor属性,那么事务只会在遇到RuntimeException的时候才会回滚,加上rollbackFor=Exception.class,可以让事务在遇到非运行时异常时也回滚。 @Transactional 注解一般可以作用在类或者方法上。 作用于类：当把@Transactional 注解放在类上时，表示所有该类的 public 方法都配置相同的事务属性信息。 作用于方法：当类配置了@Transactional，方法也配置了@Transactional，方法的事务会覆盖类的事务配置信息。 11. 测试相关@ActiveProfiles一般作用于测试类上， 用于声明生效的 Spring 配置文件。 123456@SpringBootTest(webEnvironment = RANDOM_PORT)@ActiveProfiles(&quot;test&quot;)@Slf4jpublic abstract class TestBase { ......} @Test声明一个方法为测试方法 @Transactional被声明的测试方法的数据会回滚，避免污染测试数据。 @WithMockUser Spring Security 提供的，用来模拟一个真实用户，并且可以赋予权限。 1234567@Test@Transactional@WithMockUser(username = &quot;user-id-18163138155&quot;, authorities = &quot;ROLE_TEACHER&quot;)void should_import_student_success() throws Exception { ......}","link":"/2022/02/02/SpringBoot/"},{"title":"mybatis","text":"1、#{}和${}的区别是什么？${}是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换，比如${driver}会被静态替换为com.mysql.jdbc. Driver。 #{}是 sql 的参数占位符，MyBatis 会将 sql 中的#{}替换为？号，在 sql 执行前会使用 PreparedStatement 的参数设置方法，按序给 sql 的? 号占位符设置参数值，比如 ps.setInt(0, parameterValue)，#{item.name} 的取值方式为使用反射从参数对象中获取 item 对象的 name 属性值，相当于 param.getItem().getName()。 2、Xml 映射文件中，除了常见的 select|insert|update|delete 标签之外，还有哪些标签？&lt;resultMap&gt; 、 &lt;parameterMap&gt; 、 &lt;sql&gt; 、 &lt;include&gt; 、 &lt;selectKey&gt; ，加上动态 sql 的 9 个标签， trim|where|set|foreach|if|choose|when|otherwise|bind 等，其中 为 sql 片段标签，通过 &lt;include&gt; 标签引入 sql 片段， &lt;selectKey&gt; 为不支持自增的主键生成策略标签。 3、最佳实践中，通常一个 Xml 映射文件，都会写一个 Dao 接口与之对应，请问，这个 Dao 接口的工作原理是什么？Dao 接口里的方法，参数不同时，方法能重载吗？Dao 接口，就是人们常说的 Mapper 接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名，就是映射文件中 MappedStatement 的 id 值，接口方法内的参数，就是传递给 sql 的参数。 Mapper 接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为 key 值，可唯一定位一个 MappedStatement 举例： com.mybatis3.mappers. StudentDao.findStudentById ，可以唯一找到 namespace 为 com.mybatis3.mappers. StudentDao 下面 id = findStudentById 的 MappedStatement 。在 MyBatis 中，每一个 &lt;select&gt; 、 &lt;insert&gt; 、 &lt;update&gt; 、 &lt;delete&gt; 标签，都会被解析为一个 MappedStatement 对象。 Dao 接口里的方法可以重载，但是 Mybatis 的 XML 里面的 ID 不允许重复。 Mybatis 的 Dao 接口可以有多个重载方法，但是多个接口对应的映射必须只有一个，否则启动会报错。 Dao 接口里的方法可以重载，但是 Mybatis 的 XML 里面的 ID 不允许重复！ Dao 接口的工作原理是 JDK 动态代理，MyBatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行 MappedStatement 所代表的 sql，然后将 sql 执行结果返回。 Dao 接口方法可以重载，但是需要满足以下条件： 仅有一个无参方法和一个有参方法 多个有参方法时，参数数量必须一致。且使用相同的 @Param ，或者使用 param1 这种 4、MyBatis 是如何进行分页的？分页插件的原理是什么？(1) MyBatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的内存分页，而非物理分页； (2) 可以在 sql 内直接书写带有物理分页的参数来完成物理分页功能 (3) 也可以使用分页插件来完成物理分页。 分页插件的基本原理是使用 MyBatis 提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 sql，然后重写 sql，根据 dialect 方言，添加对应的物理分页语句和物理分页参数。 5、简述 MyBatis 的插件运行原理，以及如何编写一个插件。MyBatis 仅可以编写针对 ParameterHandler 、 ResultSetHandler 、 StatementHandler 、 Executor 这 4 种接口的插件，MyBatis 使用 JDK 的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 InvocationHandler 的 invoke() 方法，当然，只会拦截那些你指定需要拦截的方法。 实现 MyBatis 的 Interceptor 接口并复写 intercept() 方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，别忘了在配置文件中配置你编写的插件。 6、MyBatis 执行批量插入，能返回数据库主键列表吗？能，JDBC 都能，MyBatis 当然也能。 7、MyBatis 动态 sql 是做什么的？都有哪些动态 sql？能简述一下动态 sql 的执行原理不？MyBatis 动态 sql 可以让我们在 Xml 映射文件内，以标签的形式编写动态 sql，完成逻辑判断和动态拼接 sql 的功能，MyBatis 提供了 9 种动态 sql 标签 trim|where|set|foreach|if|choose|when|otherwise|bind 。 其执行原理为，使用 OGNL 从 sql 参数对象中计算表达式的值，根据表达式的值动态拼接 sql，以此来完成动态 sql 的功能。 8、MyBatis 是如何将 sql 执行结果封装为目标对象并返回的？都有哪些映射形式？第一种是使用 &lt;resultMap&gt; 标签，逐一定义列名和对象属性名之间的映射关系。第二种是使用 sql 列的别名功能，将列别名书写为对象属性名，比如 T_NAME AS NAME，对象属性名一般是 name，小写，但是列名不区分大小写，MyBatis 会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成 T_NAME AS NaMe，MyBatis 一样可以正常工作。 有了列名与属性名的映射关系后，MyBatis 通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。 9、MyBatis 能执行一对一、一对多的关联查询吗？都有哪些实现方式，以及它们之间的区别。关联对象查询，有两种实现方式，一种是单独发送一个 sql 去查询关联对象，赋给主对象，然后返回主对象。另一种是使用嵌套查询，嵌套查询的含义为使用 join 查询，一部分列是 A 对象的属性值，另外一部分列是关联对象 B 的属性值，好处是只发一个 sql 查询，就可以把主对象和其关联对象查出来。 那么问题来了，join 查询出来 100 条记录，如何确定主对象是 5 个，而不是 100 个？其去重复的原理是 &lt;resultMap&gt; 标签内的 &lt;id&gt; 子标签，指定了唯一确定一条记录的 id 列，MyBatis 根据 &lt;id&gt; 列值来完成 100 条记录的去重复功能， &lt;id&gt; 可以有多个，代表了联合主键的语意。 同样主对象的关联对象，也是根据这个原理去重复的，尽管一般情况下，只有主对象会有重复记录，关联对象一般不会重复。 10、MyBatis 是否支持延迟加载？如果支持，它的实现原理是什么？MyBatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载，association 指的就是一对一，collection 指的就是一对多查询。在 MyBatis 配置文件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。 它的原理是，使用 CGLIB 创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用 a.getB().getName() ，拦截器 invoke() 方法发现 a.getB() 是 null 值，那么就会单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上来，然后调用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName() 方法的调用。这就是延迟加载的基本原理。 当然了，不光是 MyBatis，几乎所有的包括 Hibernate，支持延迟加载的原理都是一样的。 11、MyBatis 的 Xml 映射文件中，不同的 Xml 映射文件，id 是否可以重复？不同的 Xml 映射文件，如果配置了 namespace，那么 id 可以重复；如果没有配置 namespace，那么 id 不能重复；毕竟 namespace 不是必须的，只是最佳实践而已。 原因就是 namespace+id 是作为 Map&lt;String, MappedStatement&gt; 的 key 使用的，如果没有 namespace，就剩下 id，那么，id 重复会导致数据互相覆盖。有了 namespace，自然 id 就可以重复，namespace 不同，namespace+id 自然也就不同。 12、MyBatis 中如何执行批处理？使用 BatchExecutor 完成批处理。 13、MyBatis 都有哪些 Executor 执行器？它们之间的区别是什么？MyBatis 有三种基本的 Executor 执行器SimpleExecutor 、 ReuseExecutor 、 BatchExecutor SimpleExecutor ：每执行一次 update 或 select，就开启一个 Statement 对象，用完立刻关闭 Statement 对象。 ReuseExecutor ：执行 update 或 select，以 sql 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map&lt;String, Statement&gt;内，供下一次使用。简言之，就是重复使用 Statement 对象。 BatchExecutor ：执行 update（没有 select，JDBC 批处理不支持 select），将所有 sql 都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个 Statement 对象，每个 Statement 对象都是 addBatch()完毕后，等待逐一执行 executeBatch()批处理。与 JDBC 批处理相同。 作用范围：Executor 的这些特点，都严格限制在 SqlSession 生命周期范围内。 14、MyBatis 中如何指定使用哪一种 Executor 执行器？在 MyBatis 配置文件中，可以指定默认的 ExecutorType 执行器类型，也可以手动给 DefaultSqlSessionFactory 的创建 SqlSession 的方法传递 ExecutorType 类型参数。 15、MyBatis 是否可以映射 Enum 枚举类？MyBatis 可以映射枚举类，不单可以映射枚举类，MyBatis 可以映射任何对象到表的一列上。映射方式为自定义一个 TypeHandler ，实现 TypeHandler 的 setParameter() 和 getResult() 接口方法。 TypeHandler 有两个作用，一是完成从 javaType 至 jdbcType 的转换，二是完成 jdbcType 至 javaType 的转换，体现为 setParameter() 和 getResult() 两个方法，分别代表设置 sql 问号占位符参数和获取列查询结果。 16、MyBatis 映射文件中，如果 A 标签通过 include 引用了 B 标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在 A 标签的前面？虽然 MyBatis 解析 Xml 映射文件是按照顺序解析的，但是，被引用的 B 标签依然可以定义在任何地方，MyBatis 都可以正确识别。 原理是，MyBatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，MyBatis 会将 A 标签标记为未解析状态，然后继续解析余下的标签，包含 B 标签，待所有标签解析完毕，MyBatis 会重新解析那些被标记为未解析的标签，此时再解析 A 标签时，B 标签已经存在，A 标签也就可以正常解析完成了。 17、简述 MyBatis 的 Xml 映射文件和 MyBatis 内部数据结构之间的映射关系？MyBatis 将所有 Xml 配置信息都封装到 All-In-One 重量级对象 Configuration 内部。在 Xml 映射文件中， &lt;parameterMap&gt; 标签会被解析为 ParameterMap 对象，其每个子元素会被解析为 ParameterMapping 对象。 标签会被解析为 ResultMap 对象，其每个子元素会被解析为 ResultMapping 对象。每一个 &lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt; 标签均会被解析为 MappedStatement 对象，标签内的 sql 会被解析为 BoundSql 对象。 18、为什么说 MyBatis 是半自动 ORM 映射工具？它与全自动的区别在哪里？Hibernate 属于全自动 ORM 映射工具，使用 Hibernate 查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而 MyBatis 在查询关联对象或关联集合对象时，需要手动编写 sql 来完成，所以，称之为半自动 ORM 映射工具。","link":"/2022/02/02/mybatis/"},{"title":"Java 注解","text":"1、注解的理解 从JDK 5.0 开始, Java 增加了对元数据(MetaData) 的支持, 也就是Annotation(注解) Annotation 其实就是代码里的特殊标记, 这些标记可以在编译, 类加载, 运行时被读取, 并执行相应的处理。通过使用Annotation, 程序员可以在不改变原有逻辑的情况下, 在源文件中嵌入一些补充信息。代码分析工具、开发工具和部署工具可以通过这些补充信息进行验证或者进行部署。 Annotation 可以像修饰符一样被使用, 可用于修饰包,类, 构造器, 方法, 成员变量, 参数, 局部变量的声明, 这些信息被保存在Annotation 的“name=value” 对中。 在JavaSE中，注解的使用目的比较简单，例如标记过时的功能，忽略警告等。在JavaEE/Android中注解占据了更重要的角色，例如用来配置应用程序的任何切面，代替JavaEE旧版中所遗留的繁冗代码和XML配置等。 未来的开发模式都是基于注解的，JPA是基于注解的，Spring2.5以上都是基于注解的，Hibernate3.x以后也是基于注解的，现在的Struts2有一部分也是基于注解的了，注解是一种趋势，一定程度上可以说：框架= 注解+ 反射+ 设计模式。 2、Annotation的使用示例 使用Annotation 时要在其前面增加@ 符号, 并把该Annotation 当成一个修饰符使用。用于修饰它支持的程序元素 示例一：生成文档相关的注解 @author标明开发该类模块的作者，多个作者之间使用,分割 @version标明该类模块的版本 @see参考转向，也就是相关主题 @since从哪个版本开始增加的 @param对方法中某参数的说明，如果没有参数就不能写 @return对方法返回值的说明，如果方法的返回值类型是void就不能写 @exception对方法可能抛出的异常进行说明，如果方法没有用throws显式抛出的异常就不能写其中 @param、@return和@exception这三个标记都是只用于方法的。 @param的格式要求：@param形参名形参类型形参说明 @return的格式要求：@return返回值类型返回值说明 @exception的格式要求：@exception异常类型异常说明 @param和@exception可以并列多个 示例二：在编译时进行格式检查(JDK内置的三个基本注解) @Override: 限定重写父类方法, 该注解只能用于方法 @Deprecated: 用于表示所修饰的元素(类, 方法等)已过时。通常是因为所修饰的结构危险或存在更好的选择 @SuppressWarnings: 抑制编译器警告 示例三：跟踪代码依赖性，实现替代配置文件功能 Servlet3.0提供了注解(annotation),使得不再需要在web.xml文件中进行Servlet的部署。 spring框架中关于“事务”的管理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import java.util.ArrayList;import java.util.Date;/** * 注解的使用 * * 1. 理解Annotation: * ① jdk 5.0 新增的功能 * * ② Annotation 其实就是代码里的特殊标记, 这些标记可以在编译, 类加载, 运行时被读取, 并执行相应的处理。通过使用 Annotation, * 程序员可以在不改变原有逻辑的情况下, 在源文件中嵌入一些补充信息。 * * ③在JavaSE中，注解的使用目的比较简单，例如标记过时的功能，忽略警告等。在JavaEE/Android * 中注解占据了更重要的角色，例如用来配置应用程序的任何切面，代替JavaEE旧版中所遗留的繁冗 * 代码和XML配置等。 * * 2. Annocation的使用示例 * 示例一：生成文档相关的注解 * 示例二：在编译时进行格式检查(JDK内置的三个基本注解) * @Override: 限定重写父类方法, 该注解只能用于方法 * @Deprecated: 用于表示所修饰的元素(类, 方法等)已过时。通常是因为所修饰的结构危险或存在更好的选择 * @SuppressWarnings: 抑制编译器警告 * * 示例三：跟踪代码依赖性，实现替代配置文件功能 */public class AnnotationTest { public static void main(String[] args) { Person p = new Student(); p.walk(); Date date = new Date(2020, 10, 11); System.out.println(date); @SuppressWarnings(&quot;unused&quot;) int num = 10;// System.out.println(num); @SuppressWarnings({ &quot;unused&quot;, &quot;rawtypes&quot; }) ArrayList list = new ArrayList(); }}class Person{ private String name; private int age; public Person() { super(); } public Person(String name, int age) { this.name = name; this.age = age; } public void walk(){ System.out.println(&quot;学习中……&quot;); } public void eat(){ System.out.println(&quot;摸鱼中……&quot;); }}interface Info{ void show();}class Student extends Person implements Info{ @Override public void walk() { System.out.println(&quot;喷子走开&quot;); } @Override public void show() { }} 3、如何自定义注解 定义新的Annotation类型使用@interface关键字 自定义注解自动继承了java.lang.annotation.Annotation接口 Annotation的成员变量在Annotation定义中以无参数方法的形式来声明。其方法名和返回值定义了该成员的名字和类型。我们称为配置参数。类型只能是八种基本数据类型、String类型、Class类型、enum类型、Annotation类型、以上所有类型的数组。 可以在定义Annotation的成员变量时为其指定初始值,指定成员变量的初始值可使用default关键字 如果只有一个参数成员，建议使用参数名为value 如果定义的注解含有配置参数，那么使用时必须指定参数值，除非它有默认值。格式是“参数名=参数值”，如果只有一个参数成员，且名称为value，可以省略“value=” 没有成员定义的Annotation称为标记;包含成员变量的Annotation称为元数据Annotation 注意：自定义注解必须配上注解的信息处理流程才有意义。 123456789101112131415161718192021public @interface MyAnnotation { String value();}/** * 注解的使用 * * 3.如何自定义注解：参照@SuppressWarnings定义 * ① 注解声明为：@interface * ② 内部定义成员，通常使用value表示 * ③ 可以指定成员的默认值，使用default定义 * ④ 如果自定义注解没有成员，表明是一个标识作用。 * * 如果注解有成员，在使用注解时，需要指明成员的值。 * 自定义注解必须配上注解的信息处理流程(使用反射)才有意义。 * 自定义注解通过都会指明两个元注解：Retention、Target * */@MyAnnotation(value = &quot;hello&quot;) 4、jdk中4个基本的元注解的使用 上JDK 的元Annotation 用于修饰其他Annotation 定义 JDK5.0提供了4个标准的meta-annotation类型，分别是： Retention Target Documented Inherited 元数据的理解：String name = “MyBlog”; @Retention: 只能用于修饰一个Annotation定义, 用于指定该Annotation 的生命周期, @Rentention包含一个RetentionPolicy类型的成员变量, 使用@Rentention时必须为该value 成员变量指定值： RetentionPolicy.SOURCE:在源文件中有效（即源文件保留），编译器直接丢弃这种策略的注释 RetentionPolicy.CLASS:在class文件中有效（即class保留），当运行Java 程序时, JVM 不会保留注解。这是默认值 RetentionPolicy.RUNTIME:在运行时有效（即运行时保留），当运行Java 程序时, JVM 会保留注释。程序可以通过反射获取该注释。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;@Retention(RetentionPolicy.SOURCE)public @interface MyAnnotation { String value();}/** * 注解的使用 * * 4.jdk 提供的4种元注解 * 元注解：对现有的注解进行解释说明的注解 * Retention:指定所修饰的 Annotation 的生命周期：SOURCE\\CLASS（默认行为）\\RUNTIME * 只有声明为RUNTIME生命周期的注解，才能通过反射获取。 * Target: * Documented: * Inherited: * */public class AnnotationTest { public static void main(String[] args) { }}@MyAnnotation(value = &quot;hello&quot;)class Person{ private String name; private int age; public Person() { super(); } @MyAnnotation(value = &quot;jack&quot;) public Person(String name, int age) { this.name = name; this.age = age; } public void walk(){ System.out.println(&quot;学习中……&quot;); } public void eat(){ System.out.println(&quot;摸鱼中……&quot;); }} 5、jdk中4个基本的元注解的使用 下@Target: 用于修饰Annotation 定义, 用于指定被修饰的Annotation 能用于修饰哪些程序元素。@Target 也包含一个名为value的成员变量。 @Documented: 用于指定被该元Annotation 修饰的Annotation 类将被javadoc工具提取成文档。默认情况下，javadoc是不包括注解的。 定义为Documented的注解必须设置Retention值为RUNTIME。 @Inherited: 被它修饰的Annotation 将具有继承性。如果某个类使用了被@Inherited 修饰的Annotation, 则其子类将自动具有该注解。 比如：如果把标有@Inherited注解的自定义的注解标注在类级别上，子类则可以继承父类类级别的注解 实际应用中，使用较少 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import org.junit.Test;import java.lang.annotation.Annotation;import java.util.ArrayList;import java.util.Date;/** * 注解的使用 * * 4.jdk 提供的4种元注解 * 元注解：对现有的注解进行解释说明的注解 * Retention:指定所修饰的 Annotation 的生命周期：SOURCE\\CLASS（默认行为）\\RUNTIME * 只有声明为RUNTIME生命周期的注解，才能通过反射获取。 * Target:用于指定被修饰的 Annotation 能用于修饰哪些程序元素 * *******出现的频率较低******* * Documented:表示所修饰的注解在被javadoc解析时，保留下来。 * Inherited:被它修饰的 Annotation 将具有继承性。 * * 5.通过反射获取注解信息 ---到反射内容时系统讲解 */public class AnnotationTest { public static void main(String[] args) { } @Test public void testGetAnnotation(){ Class clazz = Student.class; Annotation[] annotations = clazz.getAnnotations(); for(int i = 0;i &lt; annotations.length;i++){ System.out.println(annotations[i]); } }}@MyAnnotation(value = &quot;hello&quot;)class Person{ private String name; private int age; public Person() { super(); } @MyAnnotation public Person(String name, int age) { this.name = name; this.age = age; } @MyAnnotation public void walk(){ System.out.println(&quot;学习中……&quot;); } public void eat(){ System.out.println(&quot;摸鱼中……&quot;); }}@Inherited@Retention(RetentionPolicy.RUNTIME)@Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE,TYPE_PARAMETER,TYPE_USE})public @interface MyAnnotation { String value() default &quot;book&quot;;}","link":"/2022/01/13/java%E6%B3%A8%E8%A7%A3/"},{"title":"基础","text":"增强 for 循环12345678for(声明语句 : 表达式){ //代码句子}声明语句：声明新的局部变量，该变量的类型必须和数组元素的类型匹配。其作用域限定在循环语句块，其值与此时数组元素的值相等。表达式：表达式是要访问的数组名，或者是返回值为数组的方法 修饰符访问控制优先级 操作符 Number &amp; Math 类方法xxxValue() 方法用于将 Number 对象转换为 xxx 数据类型的值并返回。 （xxx处可为byte、double、float、int、long、short） compareTo() 方法用于将 Number 对象与方法的参数进行比较。可用于比较 Byte, Long, Integer等。该方法用于两个相同数据类型的比较，两个不同类型的数据不能用此方法来比较。 valueOf() 方法用于返回给定参数的原生 Number 对象值，参数可以是原生数据类型, String等。该方法是静态方法。该方法可以接收两个参数一个是字符串，一个是基数(进制)。 object 类 continue、break 和 return 的区别是什么？continue ：指跳出当前的这一次循环，继续下一次循环。 break ：指跳出整个循环体，继续执行循环下面的语句。 return 用于跳出所在方法，结束该方法的运行。 静态方法为什么不能调用非静态成员?静态方法是属于类的，在类加载的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。 在类的非静态成员不存在的时候静态成员就已经存在了，此时调用在内存中还不存在的非静态成员，属于非法操作。 == 和 equals() 的区别对于基本数据类型来说，== 比较的是值。对于引用数据类型来说，== 比较的是对象的内存地址。 因为 Java 只有值传递，所以，对于 == 来说，不管是比较基本数据类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。 equals() 不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等。equals()方法存在于Object类中，而Object类是所有类的直接或间接父类，因此所有的类都有equals()方法。 String equals() 和 Object equals() 有何区别？String 中的 equals 方法是被重写过的，比较的是 String 字符串的值是否相等。 Object 的 equals 方法是比较的对象的内存地址。 hashcode的用处当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashCode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashCode 值作比较，如果没有相符的 hashCode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashCode 值的对象，这时会调用 equals() 方法来检查 hashCode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。 那为什么不只提供 hashCode() 方法呢？这是因为两个对象的 hashCode值相等并不代表 两个对象就相等。 那为什么两个对象有相同的 hashCode 值，它们也不一定是相等的？因为 hashCode() 所使用的哈希算法也许刚好会让多个对象传回相同的哈希值。越糟糕的哈希算法越容易碰撞，但这也与数据值域分布的特性有关（所谓哈希碰撞也就是指的是不同的对象得到相同的 hashCode )。 总结 ：如果两个对象的hashCode值相等，那这两个对象不一定相等（哈希碰撞）。 如果两个对象的hashCode值相等并且equals()方法也返回 true，我们才认为这两个对象相等。 如果两个对象的hashCode 值不相等，我们就可以直接认为这两个对象不相等。 为什么重写 equals() 时必须重写 hashCode() 方法？因为两个相等的对象的 hashCode 值必须是相等。也就是说如果 equals 方法判断两个对象是相等的，那这两个对象的 hashCode 值也要相等。如果重写 equals() 时没有重写 hashCode() 方法的话就可能会导致 equals 方法判断是相等的两个对象，hashCode值却不相等。 对象的相等与指向他们的引用相等,两者有什么不同?对象的相等一般比较的是内存中存放的内容是否相等。 引用相等一般比较的是他们指向的内存地址是否相等。 对象实体与对象引用有何不同?new创建对象实例（对象实例在堆内存中），对象引用指向对象实例（对象引用存放在栈内存中）。 一个对象引用可以指向 0 个或 1 个对象（一根绳子可以不系气球，也可以系一个气球）;一个对象可以有 n 个引用指向它（可以用 n 条绳子系住一个气球）。 面向对象三大特征1、封装 2、继承 3、多态 接口和抽象类有什么共同点和区别？共同点： 都不能被实例化。 都可以包含抽象方法。 都可以有默认实现的方法（Java 8 可以用 default 关键在接口中定义默认方法）。 区别 ： 接口主要用于对类的行为进行约束，你实现了某个接口就具有了对应的行为。抽象类主要用于代码复用，强调的是所属关系（比如说我们抽象了一个发送短信的抽象类，）。 一个类只能继承一个类，但是可以实现多个接口。 接口中的成员变量只能是 public static final 类型的，不能被修改且必须有初始值，而抽象类的成员变量默认 default，可在子类中被重新定义，也可被重新赋值。 深拷贝和浅拷贝区别？什么是引用拷贝？浅拷贝：浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同一个内部对象。 深拷贝 ：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。 引用拷贝: 两个不同的引用指向同一个对象。 String、StringBuffer、StringBuilder 的区别？String 为什么是不可变的?可变性 String 类中使用 final 关键字修饰字符数组来保存字符串，所以String 对象是不可变的。被 final 关键字修饰的类不能被继承，修饰的方法不能被重写，修饰的变量是基本数据类型则值不能改变，修饰的变量是引用类型则不能再指向其他对象。因此，final 关键字修饰的数组保存字符串并不是 String 不可变的根本原因，因为这个数组保存的字符串是可变的（final 修饰引用类型变量的情况）。 String 真正不可变有下面几点原因： 保存字符串的数组被 final 修饰且为私有的，并且String 类没有提供/暴露修改这个字符串的方法。 String 类被 final 修饰导致其不能被继承，进而避免了子类破坏 String 不可变。 线程安全性 String中的对象是不可变的，也就可以理解为常量，线程安全。 StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。 StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。 性能 每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。 StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 总结： 操作少量的数据: 适用 String 单线程操作字符串缓冲区下操作大量数据: 适用 StringBuilder 多线程操作字符串缓冲区下操作大量数据: 适用 StringBuffer 字符串拼接用“+” 还是 StringBuilder?对象引用和“+”的字符串拼接方式，实际上是通过 StringBuilder 调用 append() 方法实现的，拼接完成之后调用 toString() 得到一个 String 对象 。 编译器不会创建单个 StringBuilder 以复用，会导致创建过多的 StringBuilder 对象。 若StringBuilder 对象是在循环内部被创建的，这意味着每循环一次就会创建一个 StringBuilder 对象。 泛型一般有三种使用方式: 泛型类、泛型接口、泛型方法。1.泛型类： 1234567891011121314//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型//在实例化泛型类时，必须指定T的具体类型public class Generic&lt;T&gt; { private T key; public Generic(T key) { this.key = key; } public T getKey() { return key; }}实例化泛型类：Generic&lt;Integer&gt; genericInteger = new Generic&lt;Integer&gt;(123456); 2.泛型接口 ： 1234567891011121314151617实现泛型接口，不指定类型：class GeneratorImpl&lt;T&gt; implements Generator&lt;T&gt;{ @Override public T method() { return null; }}实现泛型接口，指定类型：class GeneratorImpl implements Generator&lt;String&gt;{ @Override public String method() { return &quot;hello&quot;; }} 3.泛型方法 ： 123456789101112131415public static &lt;E&gt; void printArray(E[] inputArray) { for (E element : inputArray) { System.out.printf(&quot;%s &quot;, element); } System.out.println();}使用：// 创建不同类型数组： Integer, Double 和 CharacterInteger[] intArray = { 1, 2, 3 };String[] stringArray = { &quot;Hello&quot;, &quot;World&quot; };printArray(intArray);printArray(stringArray); 常用的通配符: ？ 表示不确定的 Java 类型 T (type) 表示具体的一个 Java 类型 K V (key value) 分别代表 Java 键值中的 Key Value E (element) 代表 Element 注解只有被解析之后才会生效，常见的解析方法有两种：通过反射可以获取任意一个类的所有属性和方法，还可以调用这些方法和属性。基于反射分析类，然后获取到类/属性/方法/方法的参数上的注解,就可以做进一步的处理。 编译期直接扫描 ：编译器在编译 Java 代码的时候扫描对应的注解并处理，比如某个方法使用@Override 注解，编译器在编译的时候就会检测当前的方法是否重写了父类对应的方法。 运行期通过反射处理 ：像框架中自带的注解(比如 Spring 框架的 @Value 、@Component)都是通过反射来进行处理的。 Exception 和 Error 有什么区别？在 Java 中，所有的异常都有一个共同的祖先 java.lang 包中的 Throwable 类。Throwable 类有两个重要的子类: Exception :程序本身可以处理的异常，可以通过 catch 来进行捕获。Exception 又可以分为 Checked Exception (受检查异常，必须处理) 和 Unchecked Exception (不受检查异常，可以不处理)。 Error ：Error 属于程序无法处理的错误 ，我们没办法通过 catch 来进行捕获不建议通过catch捕获 。例如Java 虚拟机运行错误（Virtual MachineError）、虚拟机内存不够错误(OutOfMemoryError)、类定义错误（NoClassDefFoundError）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止。 Throwable 类常用方法？String getMessage(): 返回异常发生时的简要描述 String toString(): 返回异常发生时的详细信息 String getLocalizedMessage(): 返回异常对象的本地化信息。使用 Throwable 的子类覆盖这个方法，可以生成本地化信息。如果子类没有覆盖该方法，则该方法返回的信息与 getMessage()返回的结果相同 void printStackTrace(): 在控制台上打印 Throwable 对象封装的异常信息 try-catch-finallytry块： 用于捕获异常。其后可接零个或多个 catch 块，如果没有 catch 块，则必须跟一个 finally 块。 catch块： 用于处理 try 捕获到的异常。 finally 块： 无论是否捕获或处理异常，finally 块里的语句都会被执行。当在 try 块或 catch 块中遇到 return 语句时，finally 语句块将在方法返回之前被执行。 在某些情况下，finally 中的代码不会被执行。 1、finally 之前虚拟机被终止运行的话，finally 中的代码就不会被执行。 2、程序所在的线程死亡。 3、关闭 CPU。 不要在 finally 语句块中使用 return！当 try 语句和 finally 语句中都有 return 语句时，try 语句块中的 return 语句会被忽略。这是因为 try 语句中的 return 返回值会先被暂存在一个本地变量中，当执行到 finally 语句中的 return 之后，这个本地变量的值就变为了 finally 语句中的 return 返回值。 获取用键盘输入常用的两种方法方法 1：通过 Scanner 1234Scanner input = new Scanner(System.in);String s = input.nextLine();input.close();Copy to clipboardErrorCopied 方法 2：通过 BufferedReader 12BufferedReader input = new BufferedReader(new InputStreamReader(System.in));String s = input.readLine(); Java IO 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的InputStream / Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。 OutputStream / Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。 io流分类： 按照流的流向分，可以分为输入流和输出流； 按照操作单元划分，可以划分为字节流和字符流； 按照流的角色划分为节点流和处理流。 既然有了字节流,为什么还要有字符流?问题本质：不管是文件读写还是网络发送接收，信息的最小存储单元都是字节，那为什么 I/O 流操作要分为字节流操作和字符流操作呢？ 回答：字符流是由 Java 虚拟机将字节转换得到的，问题就出在这个过程还算是非常耗时，并且，如果我们不知道编码类型就很容易出现乱码问题。所以， I/O 流就干脆提供了一个直接操作字符的接口，方便我们平时对字符进行流操作。如果音频文件、图片等媒体文件用字节流比较好，如果涉及到字符的话使用字符流比较好。","link":"/2022/02/02/%E5%9F%BA%E7%A1%80/"},{"title":"并发-基础","text":"与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制。 在多线程的情况下，程序计数器用于记录当前线程执行的位置。程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。 堆和方法区堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 Java 线程状态变迁 上下文切换线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。 主动让出 CPU，比如调用了 sleep(), wait() 等。 时间片用完，因为操作系统要防止一个线程或者进程长时间占用CPU导致其他线程或者进程饿死。 调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。 被终止或结束运行 这其中前三种都会发生线程切换，线程切换意味着需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的上下文切换。 产生死锁必须具备以下四个条件： 1.互斥条件：该资源任意一个时刻只由一个线程占用。 2.请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 3.不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 4.循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 避免死锁的几个方法避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock (timeout)来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里， 否则会出现解锁失败的情况。 sleep() 方法和 wait() 方法区别和共同点? 两者最主要的区别在于：sleep() 方法没有释放锁，而 wait() 方法释放了锁 。 两者都可以暂停线程的执行。 wait() 通常被用于线程间交互/通信，sleep() 通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout) 超时后线程会自动苏醒。 为什么调用 start() 方法时会执行 run() 方法，为什么不能直接调用 run() 方法？(重要)new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。","link":"/2022/02/02/%E5%B9%B6%E5%8F%91-%E5%9F%BA%E7%A1%80/"},{"title":"并发-容器","text":"容器大部分在 java.util.concurrent 包中。 ConcurrentHashMap : 线程安全的 HashMap CopyOnWriteArrayList : 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector。 ConcurrentLinkedQueue : 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。 BlockingQueue : 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。 ConcurrentSkipListMap : 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。 ConcurrentHashMap我们知道 HashMap 不是线程安全的，在并发场景下如果要保证一种可行的方式是使用 Collections.synchronizedMap() 方法来包装我们的 HashMap。但这是通过使用一个全局的锁来同步不同线程间的并发访问，因此会带来不可忽视的性能问题。 所以就有了 HashMap 的线程安全版本—— ConcurrentHashMap 在 ConcurrentHashMap 中，无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。 CopyOnWriteArrayListCopyOnWriteArrayList 简介123public class CopyOnWriteArrayList&lt;E&gt;extends Objectimplements List&lt;E&gt;, RandomAccess, Cloneable, Serializable 在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问 List 的内部数据，毕竟读取操作是安全的。 这和我们之前在多线程章节讲过 ReentrantReadWriteLock 读写锁的思想非常类似，也就是读读共享、写写互斥、读写互斥、写读互斥。JDK 中提供了 CopyOnWriteArrayList 类比相比于在读写锁的思想又更进一步。为了将读取的性能发挥到极致，CopyOnWriteArrayList 读取是完全不用加锁的，并且更厉害的是：写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待。这样一来，读操作的性能就会大幅度提升。 CopyOnWriteArrayList 是如何做到的？CopyOnWriteArrayList 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。 从 CopyOnWriteArrayList 的名字就能看出 CopyOnWriteArrayList 是满足 CopyOnWrite 的。所谓 CopyOnWrite 也就是说：在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。 ConcurrentLinkedQueueJava 提供的线程安全的 Queue 可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是 ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。 从名字可以看出，ConcurrentLinkedQueue这个队列使用链表作为其数据结构．ConcurrentLinkedQueue 应该算是在高并发环境中性能最好的队列了。它之所有能有很好的性能，是因为其内部复杂的实现。ConcurrentLinkedQueue 主要使用 CAS 非阻塞算法来实现线程安全就好了。 ConcurrentLinkedQueue 适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 ConcurrentLinkedQueue 来替代。 BlockingQueue阻塞队列——BlockingQueue。阻塞队列（BlockingQueue）被广泛使用在“生产者-消费者”问题中，其原因是 BlockingQueue 提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。 BlockingQueue 是一个接口，继承自 Queue，所以其实现类也可以作为 Queue 的实现来使用，而 Queue 又继承自 Collection 接口。 有3 个常见的 BlockingQueue 的实现类：ArrayBlockingQueue、EELinkedBlockingQueue 、PriorityBlockingQueue ArrayBlockingQueueArrayBlockingQueue 是 BlockingQueue 接口的有界队列实现类，底层采用数组来实现。 123public class ArrayBlockingQueue&lt;E&gt;extends AbstractQueue&lt;E&gt;implements BlockingQueue&lt;E&gt;, Serializable{} ArrayBlockingQueue 一旦创建，容量不能改变。其并发控制采用可重入锁 ReentrantLock ，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。 ArrayBlockingQueue 默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到 ArrayBlockingQueue。而非公平性则是指访问 ArrayBlockingQueue 的顺序不是遵守严格的时间顺序，有可能存在，当 ArrayBlockingQueue 可以被访问时，长时间阻塞的线程依然无法访问到 ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。如果需要获得公平性的 ArrayBlockingQueue,可采用： 1private static ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(10,true); LinkedBlockingQueueLinkedBlockingQueue 底层基于 单向链表 实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足 FIFO 的特性，与 ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建 LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于 Integer.MAX_VALUE 。 PriorityBlockingQueuePriorityBlockingQueue 是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 compareTo() 方法来指定元素排序规则，或者初始化时通过构造器参数 Comparator 来指定排序规则。 PriorityBlockingQueue 并发控制采用的是可重入锁 ReentrantLock，队列为无界队列（ArrayBlockingQueue 是有界队列，LinkedBlockingQueue 也可以通过在构造函数中传入 capacity 指定队列最大的容量，但是 PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容）。 简单地说，它就是 PriorityQueue 的线程安全版本。不可以插入 null 值，同时，插入队列的对象必须是可比较大小的（comparable），否则报 ClassCastException 异常。它的插入操作 put 方法不会 block，因为它是无界队列（take 方法在队列为空的时候会阻塞）。 ConcurrentSkipListMap对于一个单链表，即使链表是有序的，如果我们想要在其中查找某个数据，也只能从头到尾遍历链表，这样效率自然就会很低，跳表就不一样了。跳表是一种可以用来快速查找的数据结构，有点类似于平衡树。它们都可以对元素进行快速的查找。但一个重要的区别是：对平衡树的插入和删除往往很可能导致平衡树进行一次全局的调整。而对跳表的插入和删除只需要对整个数据结构的局部进行操作即可。这样带来的好处是：在高并发的情况下，你会需要一个全局锁来保证整个平衡树的线程安全。而对于跳表，你只需要部分锁即可。这样，在高并发环境下，你就可以拥有更好的性能。而就查询的性能而言，跳表的时间复杂度也是 O(logn) 所以在并发数据结构中，JDK 使用跳表来实现一个 Map。 跳表的本质是同时维护了多个链表，并且链表是分层的，最低层的链表维护了跳表内所有的元素，每上面一层链表都是下面一层的子集。 跳表内的所有链表的元素都是排序的。查找时，可以从顶级链表开始找。一旦发现被查找的元素大于当前链表中的取值，就会转入下一层链表继续找。这也就是说在查找过程中，搜索是跳跃式的。 跳表是一种利用空间换时间的算法。 使用跳表实现 Map 和使用哈希算法实现 Map 的另外一个不同之处是：哈希并不会保存元素的顺序，而跳表内所有的元素都是排序的。因此在对跳表进行遍历时，你会得到一个有序的结果。所以，如果你的应用需要有序性，那么跳表就是你不二的选择。JDK 中实现这一数据结构的类是 ConcurrentSkipListMap。","link":"/2022/02/02/%E5%B9%B6%E5%8F%91-%E5%AE%B9%E5%99%A8/"},{"title":"数据库","text":"MySQLInnoDB支持行级锁、支持事务、支持外键、依赖于 redo log支持数据库异常崩溃后的安全恢复，支持 MVCC（MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提供性能。） 表级锁和行级锁对比：表级锁： MySQL 中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。 行级锁： MySQL 中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 InnoDB 存储引擎的锁的算法有三种：Record lock：记录锁，单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 Next-key lock：record+gap 临键锁，锁定一个范围，包含记录本身 关系型数据库的事务都有 ACID 特性：事务是逻辑上的一组操作，要么都执行，要么都不执行。 原子性（Atomicity） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 数据事务的实现原理呢？MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，使用 undo log(回滚日志) 来保证事务的原子性。 MySQL InnoDB 引擎通过 锁机制、MVCC 等手段来保证事务的隔离性（ 默认支持的隔离级别是 REPEATABLE-READ ）。 并发事务带来哪些问题?在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。 脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。 不可重复读（Unrepeatable read）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。不可重复读和幻读区别： 不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次查询同一条查询语句（DQL）时，记录发现记录增多或减少了。 MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。MySQL InnoDB 的 REPEATABLE-READ（可重读）并不保证避免幻读，需要应用使用加锁读来保证。而这个加锁读使用到的机制就是 Next-Key Locks。 因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是 InnoDB 存储引擎默认使用 REPEATABLE-READ（可重读） 并不会有任何性能损失。 InnoDB 存储引擎在 分布式事务 的情况下一般会用到 SERIALIZABLE(可串行化) 隔离级别。 查询缓存执行查询语句的时候，会先查询缓存。不过，MySQL 8.0 版本后移除，因为这个功能不太实用。缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。 drop、delete 与 truncate 区别？用法不同drop(丢弃数据): drop table 表名 ，直接将表都删除掉，在删除表的时候使用。 truncate (清空数据) : truncate table 表名 ，只删除表中的数据，再插入数据的时候自增长 id 又从 1 开始，在清空表中数据的时候使用。 delete（删除数据） : delete from 表名 where 列名=值，删除某一行的数据，如果不加 where 子句和truncate table 表名作用类似。 truncate 和不带 where 子句的 delete、以及 drop 都会删除表内的数据，但是 truncate 和 delete 只删除数据不删除表的结构(定义)，执行 drop 语句，此表的结构也会删除，也就是执行 drop 之后对应的表不复存在。 属于不同的数据库语言truncate 和 drop 属于 DDL(数据定义语言)语句，操作立即生效，原数据不放到 rollback segment 中，不能回滚，操作不触发 trigger。 delete 语句是 DML (数据库操作语言)语句，这个操作会放到 rollback segement 中，事务提交之后才生效。","link":"/2022/02/02/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"索引","text":"何为索引？有什么作用？索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有: B 树， B+树和 Hash。 索引的优缺点优点 ： 使用索引可以大大加快 数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 缺点 ： 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。 索引需要使用物理文件存储，也会耗费一定空间。 使用索引一定能提高查询性能吗? 大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。 索引的底层数据结构Hash表 &amp; B+树哈希表是键值对的集合，通过键(key)即可快速取出对应的值(value)，因此哈希表可以快速检索数据（接近 O(1)）。 为何能够通过 key 快速取出 value呢？ 原因在于 哈希算法（也叫散列算法）。通过哈希算法，我们可以快速找到 key 对应的 index，找到了 index 也就找到了对应的 value。 哈希算法有个 Hash 冲突 问题，也就是说多个不同的 key 最后得到的 index 相同。通常情况下，我们常用的解决办法是 **链地址法**。链地址法就是将哈希冲突数据存放在链表中。 就比如 JDK1.8 之前 HashMap 就是通过链地址法来解决哈希冲突的。不过，JDK1.8 以后HashMap为了减少链表过长的时候搜索时间过长引入了红黑树。 既然哈希表这么快，为什么MySQL 没有使用其作为索引的数据结构呢？ 1.Hash 冲突问题 ：我们上面也提到过Hash 冲突了，不过对于数据库来说这还不算最大的缺点。 2.Hash 索引不支持顺序和范围查询（Hash 索引不支持顺序和范围查询是它最大的缺点）： 假如我们要对表中的数据进行排序或者进行范围查询，那 Hash 索引可就不行了。 B 树&amp; B+树B 树也称 B-树,全称为 多路平衡查找树 ，B+ 树是 B 树的一种变体。B 树和 B+树中的 B 是 Balanced （平衡）的意思。 目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构。 B 树&amp; B+树两者有何异同呢？ B 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。 B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。 B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。 在 MySQL 中，MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是，两者的实现方式不太一样MyISAM 引擎中，B+Tree 叶节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。 InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”，而其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。 索引类型主键索引(Primary Key)数据表的主键列使用的就是主键索引。 一张数据表有只能有一个主键，并且主键不能为 null，不能重复。 在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引且不允许存在null值的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。 二级索引(辅助索引)二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。 唯一索引，普通索引，前缀索引等索引属于二级索引。 唯一索引(Unique Key) ：唯一索引也是一种约束。唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。 普通索引(Index) ：普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。 前缀索引(Prefix) ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。 全文索引(Full Text) ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。 聚集索引与非聚集索引聚集索引聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。 在 MySQL 中，InnoDB 引擎的表的 .ibd文件就包含了该表的索引和数据，对于 InnoDB 引擎表来说，该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。 聚集索引的优点聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。 聚集索引的缺点 依赖于有序的数据 ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。 更新代价大 ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改，而且聚集索引的叶子节点还存放着数据，修改代价肯定是较大的，所以对于主键索引来说，主键一般都是不可被修改的。 非聚集索引非聚集索引即索引结构和数据分开存放的索引。 二级索引属于非聚集索引。 非聚集索引的叶子节点并不一定存放数据的指针，因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。 非聚集索引的优点更新代价比聚集索引要小 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的 非聚集索引的缺点 跟聚集索引一样，非聚集索引也依赖于有序的数据 可能会二次查询(回表) :这应该是非聚集索引最大的缺点了。非聚集索引不一定回表查询。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。 覆盖索引如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。我们知道在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次。这样就会比较慢覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！ 覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了， 而无需回表查询。 创建索引的注意事项 选择合适的字段创建索引： 不为 NULL 的字段 ：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。 被频繁查询的字段 ：我们创建索引的字段应该是查询操作非常频繁的字段。 被作为条件查询的字段 ：被作为 WHERE 条件查询的字段，应该被考虑建立索引。 频繁需要排序的字段 ：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。 被经常频繁用于连接的字段 ：经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。 被频繁更新的字段应该慎重建立索引。 虽然索引能带来查询上的效率，但是维护索引的成本也是不小的。 如果一个字段不被经常查询，反而被经常修改，那么就更不应该在这种字段上建立索引了。 尽可能的考虑建立联合索引而不是单列索引。 因为索引是需要占用磁盘空间的，可以简单理解为每个索引都对应着一颗 B+树。如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后，索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。 注意避免冗余索引 。 冗余索引指的是索引的功能相同，能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引。如（name,city ）和（name ）这两个索引就是冗余索引，能够命中前者的查询肯定是能够命中后者的 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。 考虑在字符串类型的字段上使用前缀索引代替普通索引。 前缀索引仅限于字符串类型，较普通索引会占用更小的空间，所以可以考虑使用前缀索引带替普通索引。 使用索引的一些建议 对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引 避免 where 子句中对字段施加函数，这会造成无法命中索引。 在使用 InnoDB 时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键。 删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗 MySQL 5.7 可以通过查询 sys 库的 schema_unused_indexes 视图来查询哪些索引从未被使用 在使用 limit offset 查询缓慢时，可以借助索引来提高性能 MySQL 如何为表字段添加索引？1.添加 PRIMARY KEY（主键索引） 1ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 2.添加 UNIQUE(唯一索引) 1ALTER TABLE `table_name` ADD UNIQUE ( `column` ) 3.添加 INDEX(普通索引) 1ALTER TABLE `table_name` ADD INDEX index_name ( `column` ) 4.添加 FULLTEXT(全文索引) 1ALTER TABLE `table_name` ADD FULLTEXT ( `column`) 5.添加多列索引 1ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )","link":"/2022/02/02/%E7%B4%A2%E5%BC%95/"},{"title":"线程池","text":"1. 使用线程池的好处池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。 线程池提供了一种限制和管理资源（包括执行一个任务）的方式。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。 **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。 **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 2. Executor 框架2.1 简介通过 Executor 来启动线程比使用 Thread 的 start 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免 this 逃逸问题。 补充：this 逃逸是指在构造函数返回之前其他线程就持有该对象的引用. 调用尚未构造完全的对象的方法可能引发令人疑惑的错误。 Executor 框架不仅包括了线程池的管理，还提供了线程工厂、队列以及拒绝策略等。 2.2 Executor 框架结构(三大部分组成)1) 任务(Runnable /Callable)执行任务需要实现的 Runnable 接口 或 Callable接口。Runnable 接口或 Callable 接口 实现类都可以被 ThreadPoolExecutor 或 ScheduledThreadPoolExecutor 执行。 2) 任务的执行(Executor)如下图所示，包括任务执行机制的核心接口 Executor ，以及继承自 Executor 接口的 ExecutorService 接口。**ThreadPoolExecutor** (重要)和 ScheduledThreadPoolExecutor 这两个关键类实现了 ExecutorService 接口。 3) 异步计算的结果(Future)Future 接口以及 Future 接口的实现类 FutureTask 类都可以代表异步计算的结果。 当我们把 Runnable接口 或 Callable 接口 的实现类提交给 ThreadPoolExecutor 或 ScheduledThreadPoolExecutor 执行。（调用 submit() 方法时会返回一个 FutureTask 对象）","link":"/2022/02/02/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"title":"JVM-类","text":"1.类文件结构在 Java 中，JVM 可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不针对一种特定的机器，因此，Java 程序无须重新编译便可在多种不同操作系统的计算机上运行。 2.Class 文件结构总结根据 Java 虚拟机规范，Class 文件通过 ClassFile 定义，有点类似 C 语言的结构体。 ClassFile 的结构如下： 123456789101112131415161718ClassFile { u4 magic; //Class 文件的标志 u2 minor_version;//Class 的小版本号 u2 major_version;//Class 的大版本号 u2 constant_pool_count;//常量池的数量 cp_info constant_pool[constant_pool_count-1];//常量池 u2 access_flags;//Class 的访问标记 u2 this_class;//当前类 u2 super_class;//父类 u2 interfaces_count;//接口 u2 interfaces[interfaces_count];//一个类可以实现多个接口 u2 fields_count;//Class 文件的字段属性 field_info fields[fields_count];//一个类可以有多个字段 u2 methods_count;//Class 文件的方法数量 method_info methods[methods_count];//一个类可以有个多个方法 u2 attributes_count;//此类的属性表中的属性数 attribute_info attributes[attributes_count];//属性表集合} 2.1 魔数（Magic Number）每个 Class 文件的头 4 个字节称为魔数（Magic Number）,它的唯一作用是确定这个文件是否为一个能被虚拟机接收的 Class 文件。 u4 magic; //Class 文件的标志 2.2 Class 文件版本号（Minor&amp;Major Version）u2 minor_version;//Class 的小版本号 u2 major_version;//Class 的大版本号 使用 javap -v 命令来快速查看 Class 文件的版本号信息。 高版本的 Java 虚拟机可以执行低版本编译器生成的 Class 文件，但是低版本的 Java 虚拟机不能执行高版本编译器生成的 Class 文件。所以，我们在实际开发的时候要确保开发的的 JDK 版本和生产环境的 JDK 版本保持一致。 2.3 常量池（Constant Pool）u2 constant_pool_count;//常量池的数量 cp_info constant_pool[constant_pool_count-1];//常量池 常量池的数量是 constant_pool_count-1（常量池计数器是从 1 开始计数的，将第 0 项常量空出来是有特殊考虑的，索引值为 0 代表“不引用任何一个常量池项”）。 常量池主要存放两大常量：字面量和符号引用。字面量比较接近于 Java 语言层面的的常量概念，如文本字符串、声明为 final 的常量值等。而符号引用则属于编译原理方面的概念。包括下面三类常量： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 常量池中每一项常量都是一个表，这 14 种表有一个共同的特点：**开始的第一位是一个 u1 类型的标志位 -tag 来标识常量的类型，代表当前这个常量属于哪种常量类型** .class 文件可以通过javap -v class类名 指令来看一下其常量池中的信息(javap -v class类名-&gt; temp.txt ：将结果输出到 temp.txt 文件)。 2.4 访问标志(Access Flags)在常量池结束之后，紧接着的两个字节代表访问标志，这个标志用于识别一些类或者接口层次的访问信息，包括：这个 Class 是类还是接口，是否为 public 或者 abstract 类型，如果是类的话是否声明为 final 等等。 2.5 当前类（This Class）、父类（Super Class）、接口（Interfaces）索引集合u2 this_class;//当前类 u2 super_class;//父类 u2 interfaces_count;//接口 u2 interfaces[interfaces_count];//一个类可以实现多个接口 类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名，由于 Java 语言的单继承，所以父类索引只有一个，除了 java.lang.Object 之外，所有的 java 类都有父类，因此除了 java.lang.Object 外，所有 Java 类的父类索引都不为 0。 接口索引集合用来描述这个类实现了那些接口，这些被实现的接口将按 implements (如果这个类本身是接口的话则是extends) 后的接口顺序从左到右排列在接口索引集合中。 2.6 字段表集合（Fields）u2 fields_count;//Class 文件的字段的个数 field_info fields[fields_count];//一个类会可以有个字段 字段表（field info）用于描述接口或类中声明的变量。字段包括类级变量以及实例变量，但不包括在方法内部声明的局部变量。 access_flags: 字段的作用域（public ,private,protected修饰符），是实例变量还是类变量（static修饰符）,可否被序列化（transient 修饰符）,可变性（final）,可见性（volatile 修饰符，是否强制从主内存读写）。 name_index: 对常量池的引用，表示的字段的名称； descriptor_index: 对常量池的引用，表示字段和方法的描述符； attributes_count: 一个字段还会拥有一些额外的属性，attributes_count 存放属性的个数； attributes[attributes_count]: 存放具体属性具体内容。 2.7 方法表集合（Methods）u2 methods_count;//Class 文件的方法的数量 method_info methods[methods_count];//一个类可以有个多个方法 methods_count 表示方法的数量，而 method_info 表示方法表。 Class 文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方式。方法表的结构如同字段表一样，依次包括了访问标志、名称索引、描述符索引、属性表集合。 **注意**：因为volatile修饰符和transient修饰符不可以修饰方法，所以方法表的访问标志中没有这两个对应的标志，但是增加了synchronized、native、abstract等关键字修饰方法，所以也就多了这些关键字对应的标志。 2.8 属性表集合（Attributes）u2 attributes_count;//此类的属性表中的属性数 attribute_info attributes[attributes_count];//属性表集合 在 Class 文件，字段表，方法表中都可以携带自己的属性表集合，以用于描述某些场景专有的信息。与 Class 文件中其它的数据项目要求的顺序、长度和内容不同，属性表集合的限制稍微宽松一些，不再要求各个属性表具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以向属性表中写 入自己定义的属性信息，Java 虚拟机运行时会忽略掉它不认识的属性。 类加载器类加载过程类加载过程：**加载-&gt;连接-&gt;初始化**。 连接过程又可分为三步：**验证-&gt;准备-&gt;解析**。 类加载器总结JVM 中内置了三个重要的 ClassLoader，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader： BootstrapClassLoader(启动类加载器) ：最顶层的加载类，由 C++实现，负责加载 %JAVA_HOME%/lib目录下的 jar 包和类或者被 -Xbootclasspath参数指定的路径中的所有类。 ExtensionClassLoader(扩展类加载器) ：主要负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类，或被 java.ext.dirs 系统变量所指定的路径下的 jar 包。 AppClassLoader(应用程序类加载器) ：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。 双亲委派模型双亲委派模型介绍每一个类都有一个对应它的类加载器。系统中的 ClassLoader 在协同工作的时候会默认使用 双亲委派模型 。即在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，首先会把该请求委派给父类加载器的 loadClass() 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 BootstrapClassLoader 中。当父类加载器无法处理时，才由自己来处理。当父类加载器为 null 时，会使用启动类加载器 BootstrapClassLoader 作为父类加载器。 每个类加载都有一个父类加载器，双亲委派中的双亲更多地表达的是“父母这一辈”的人而已，并不是说真的有一个 Mother ClassLoader 和一个 Father ClassLoader 。另外，类加载器之间的“父子”关系也不是通过继承来体现的，是由“优先级”来决定。 双亲委派模型的好处双亲委派模型保证了 Java 程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 API 不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 java.lang.Object 类的话，那么程序运行的时候，系统就会出现多个不同的 Object 类。 如果我们不想用双亲委派模型怎么办？自定义加载器的话，需要继承 ClassLoader 。如果我们不想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 loadClass() 方法 自定义类加载器除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader。如果我们要自定义自己的类加载器，很明显需要继承 ClassLoader。 类加载过程类的生命周期一个类的完整生命周期如下： 加载-&gt;连接-&gt;初始化-&gt;使用-&gt;卸载 类加载过程系统加载 Class 类型的文件主要三步：**加载-&gt;连接-&gt;初始化**。 连接过程又可分为三步：**验证-&gt;准备-&gt;解析**。 加载类加载过程的第一步，主要完成下面 3 件事情： 通过全类名获取定义此类的二进制字节流将字节流所代表的静态存储结构转换为方法区的运行时数据结构 一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。 验证 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意： 这时候进行内存分配的仅包括类变量（ Class Variables ，即静态变量，被 static 关键字修饰的变量，只与类相关，因此被称为类变量），而不包括实例变量。实例变量会在对象实例化时随着对象一块分配在 Java 堆中。 从概念上讲，类变量所使用的内存都应当在 方法区 中进行分配。不过有一点需要注意的是：JDK 7 之前，HotSpot 使用永久代来实现方法区的时候，实现是完全符合这种逻辑概念的。 而在 JDK 7 及之后，HotSpot 已经把原本放在永久代的字符串常量池、静态变量等移动到堆中，这个时候类变量则会随着 Class 对象一起存放在 Java 堆中。 这里所设置的初始值”通常情况”下是数据类型默认的零值（如 0、0L、null、false 等），比如我们定义了public static int value=111 ，那么 value 变量在准备阶段的初始值就是 0 而不是 111（初始化阶段才会赋值）。特殊情况：比如给 value 变量加上了 final 关键字public static final int value=111 ，那么准备阶段 value 的值就被赋值为 111。 基本数据类型的零值 ： 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符 7 类符号引用进行。 符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。在程序实际运行时，只有符号引用是不够的，举个例子：在程序执行方法时，系统需要明确知道这个方法所在的位置。Java 虚拟机为每个类都准备了一张方法表来存放类中所有的方法。当需要调用一个类的方法的时候，只要知道这个方法在方法表中的偏移量就可以直接调用该方法了。通过解析操作符号引用就可以直接转变为目标方法在类中方法表的位置，从而使得方法可以被调用。 综上，解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。 初始化初始化阶段是执行初始化方法 &lt;clinit&gt; ()方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。 说明： &lt;clinit&gt; ()方法是编译之后自动生成的。 对于&lt;clinit&gt; () 方法的调用，虚拟机会自己确保其在多线程环境中的安全性。因为 &lt;clinit&gt; () 方法是带锁线程安全，所以在多线程环境下进行类初始化的话可能会引起多个进程阻塞，并且这种阻塞很难被发现。 对于初始化阶段，虚拟机严格规范了有且只有 5 种情况下，必须对类进行初始化(只有主动去使用类才会初始化类)： 当遇到 new 、 getstatic、putstatic 或 invokestatic 这 4 条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。 当 jvm 执行 new 指令时会初始化类。即当程序创建一个类的实例对象。 当 jvm 执行 getstatic 指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量会被加载到运行时常量池)。 当 jvm 执行 putstatic 指令时会初始化类。即程序给类的静态变量赋值。 当 jvm 执行 invokestatic 指令时会初始化类。即程序调用类的静态方法。 使用 java.lang.reflect 包的方法对类进行反射调用时如 Class.forname(&quot;...&quot;), newInstance() 等等。如果类没初始化，需要触发其初始化。 初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。 当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。 MethodHandle 和 VarHandle 可以看作是轻量级的反射调用机制，而要想使用这 2 个调用， 就必须先使用 findStaticVarHandle 来初始化要调用的类。 当一个接口中定义了 JDK8 新加入的默认方法（被 default 关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。 卸载卸载类即该类的 Class 对象被 GC。 卸载类需要满足 3 个要求: 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。 该类没有在其他任何地方被引用 该类的类加载器的实例已被 GC 所以，在 JVM 生命周期内，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。 只要想通一点就好了，jdk 自带的 BootstrapClassLoader, ExtClassLoader, AppClassLoader 负责加载 jdk 提供的类，所以它们(类加载器的实例)肯定不会被回收。而我们自定义的类加载器的实例是可以被回收的，所以使用我们自定义加载器加载的类是可以被卸载掉的。","link":"/2022/02/02/JVM-%E7%B1%BB/"},{"title":"集合","text":"Java 4种数组复制方式System.arraycopy &gt; clone &gt; Arrays.copyOf &gt; for List, Set, Queue, Map 四者的区别？ List(对付顺序的好帮手): 存储的元素是有序的、可重复的。 Set(注重独一无二的性质): 存储的元素是无序的、不可重复的。 Queue(实现排队功能的叫号机): 按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。 Map(用 key 来搜索的专家): 使用键值对（key-value）存储，类似于数学上的函数 y=f(x)，”x” 代表 key，”y” 代表 value，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。 集合框架底层数据结构List Arraylist： Object[ ] 数组 Vector：Object[ ] 数组 LinkedList： 双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环) Set HashSet(无序，唯一): 基于 HashMap 实现的，底层采用 HashMap 来保存元素 LinkedHashSet: LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的 LinkedHashMap 其内部是基于 HashMap 实现一样，不过还是有一点点区别的 TreeSet(有序，唯一): 红黑树(自平衡的排序二叉树) Queue PriorityQueue: Object[] 数组来实现二叉堆 ArrayQueue: Object[] 数组 + 双指针 Map HashMap： JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间 LinkedHashMap： LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。 Hashtable： 数组+链表组成的，数组是 Hashtable 的主体，链表则是主要为了解决哈希冲突而存在的 TreeMap： 红黑树（自平衡的排序二叉树） 如何选集合需要根据键值获取到元素值时就选用 Map 接口下的集合，需要排序时选择 TreeMap,不需要排序时就选择 HashMap,需要保证线程安全就选用 ConcurrentHashMap。 当我们只需要存放元素值时，就选择实现Collection 接口的集合，需要保证元素唯一时选择实现 Set 接口的集合比如 TreeSet 或 HashSet，不需要就选择实现 List 接口的比如 ArrayList 或 LinkedList，然后再根据实现这些接口的集合的特点来选用。 ListArraylist 和 Vector 的区别? ArrayList 是 List 的主要实现类，底层使用 Object[ ]存储，适用于频繁的查找工作，线程不安全 ； Vector 是 List 的古老实现类，底层使用Object[ ] 存储，线程安全的。 Arraylist 与 LinkedList 区别?1.是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 2.底层数据结构： Arraylist 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！） 3.插入和删除是否受元素位置的影响： ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 LinkedList 采用链表存储，所以，如果是在头尾插入或者删除元素不受元素位置的影响（add(E e)、addFirst(E e)、addLast(E e)、removeFirst() 、 removeLast()），近似 O(1)，如果是要在指定位置 i 插入和删除元素的话（add(int index, E element)，remove(Object o)） 时间复杂度近似为 O(n) ，因为需要先移动到指定位置再插入。 4.是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 5.内存空间占用： ArrayList 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。 setcomparable 和 Comparator 的区别 comparable 接口实际上是出自java.lang包 它有一个 compareTo(Object obj)方法用来排序 comparator接口实际上是出自 java.util 包它有一个compare(Object obj1, Object obj2)方法用来排序 一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo()方法或compare()方法，当我们需要对某一个集合实现两种排序方式，比如一个 song 对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo()方法和使用自制的Comparator方法或者以两个 Comparator 来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的 Collections.sort(). 无序性和不可重复性的含义是什么1、无序性不等于随机性 ，无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。 2、不可重复性是指添加的元素按照 equals()判断时 ，返回 false，需要同时重写 equals()方法和 HashCode()方法。 HashSet、LinkedHashSet 和 TreeSet 三者的异同 HashSet、LinkedHashSet 和 TreeSet 都是 Set 接口的实现类，都能保证元素唯一，并且都不是线程安全的。 HashSet、LinkedHashSet 和 TreeSet 的主要区别在于底层数据结构不同。HashSet 的底层数据结构是哈希表（基于 HashMap 实现）。LinkedHashSet 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。TreeSet 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。 底层数据结构不同又导致这三者的应用场景不同。HashSet 用于不需要保证元素插入和取出顺序的场景，LinkedHashSet 用于保证元素的插入和取出顺序满足 FIFO 的场景，TreeSet 用于支持对元素自定义排序规则的场景。 QueueQueue 与 Deque 的区别 Queue 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（FIFO） 规则。 Queue 扩展了 Collection 的接口，根据 因为容量问题而导致操作失败后处理方式的不同 可以分为两类方法: 一种在操作失败后会抛出异常，另一种则会返回特殊值。 Deque 是双端队列，在队列的两端均可以插入或删除元素。 Deque 扩展了 Queue 的接口, 增加了在队首和队尾进行插入和删除的方法，同样根据失败后处理方式的不同分为两类 ArrayDeque 与 LinkedList 的区别ArrayDeque 是基于可变长的数组和双指针来实现，而 LinkedList 则通过链表来实现。 ArrayDeque 不支持存储 NULL 数据，但 LinkedList 支持。 ArrayDeque 插入时可能存在扩容过程, 不过均摊后的插入操作依然为 O(1)。虽然 LinkedList 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢。 从性能的角度上，选用 ArrayDeque 来实现队列要比 LinkedList 更好。此外，ArrayDeque 也可以用于实现栈。 PriorityQueuePriorityQueue 与 Queue 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。 PriorityQueue 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据 PriorityQueue 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。 PriorityQueue 是非线程安全的，且不支持存储 NULL 和 non-comparable 的对象。 PriorityQueue 默认是小顶堆，但可以接收一个 Comparator 作为构造参数，从而来自定义元素优先级的先后。 PriorityQueue 在面试中可能更多的会出现在堆排序、求第K大的数、带权图的遍历等。 Map 接口HashMap 和 Hashtable 的区别1.线程是否安全： HashMap 是非线程安全的，Hashtable 是线程安全的,因为 Hashtable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 2.效率： 因为线程安全的问题，HashMap 要比 Hashtable 效率高一点。另外，Hashtable 基本被淘汰，不要在代码中使用它； 3.对 Null key 和 Null value 的支持： HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；Hashtable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。 4.初始容量大小和每次扩充容量大小的不同 ： ① 创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。 ② 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小（HashMap 中的tableSizeFor()方法保证，下面给出了源代码）。也就是说 HashMap 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。 5.底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 HashMap 和 HashSet 区别 HashSet 如何检查重复当你把对象加入HashSet时，HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。 hashCode()与 equals() 的相关规定： 如果两个对象相等，则 hashcode 一定也是相同的 两个对象相等,对两个 equals() 方法返回 true 两个对象有相同的 hashcode 值，它们也不一定是相等的 综上，equals() 方法被覆盖过，则 hashCode() 方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 //HashMap 的底层实现 HashMap 多线程操作导致死循环问题主要原因在于并发下的 Rehash 会造成元素之间会形成一个循环链表。不过，jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 HashMap,因为多线程下使用 HashMap 还是会存在其他问题比如数据丢失。并发环境下推荐使用 ConcurrentHashMap 。 ConcurrentHashMap 和 Hashtable 的区别底层数据结构： JDK1.7 的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟 HashMap1.8 的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；实现线程安全的方式（重要）： ① 在 JDK1.7 的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了 Segment 的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6 以后 对 synchronized 锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本； ② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 Collections 工具类排序操作123456void reverse(List list) //反转void shuffle(List list) //随机排序void sort(List list) //按自然排序的升序排序void sort(List list, Comparator c) //定制排序，由Comparator控制排序逻辑void swap(List list, int i , int j) //交换两个索引位置的元素void rotate(List list, int distance)//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面 查找,替换操作1234567int binarySearch(List list, Object key)//对List进行二分查找，返回索引，注意List必须是有序的int max(Collection coll)//根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll)int max(Collection coll, Comparator c)//根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c)void fill(List list, Object obj)//用指定的元素代替指定list中的所有元素int frequency(Collection c, Object o)//统计元素出现次数int indexOfSubList(List list, List target)//统计target在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target)boolean replaceAll(List list, Object oldVal, Object newVal)//用新元素替换旧元素 同步控制最好不要用下面这些方法，效率非常低，需要线程安全的集合类型时请考虑使用 JUC 包下的并发集合。 1234synchronizedCollection(Collection&lt;T&gt; c) //返回指定 collection 支持的同步（线程安全的）collection。synchronizedList(List&lt;T&gt; list)//返回指定列表支持的同步（线程安全的）List。synchronizedMap(Map&lt;K,V&gt; m) //返回由指定映射支持的同步（线程安全的）Map。synchronizedSet(Set&lt;T&gt; s) //返回指定 set 支持的同步（线程安全的）set。","link":"/2022/02/02/%E9%9B%86%E5%90%88/"}],"tags":[{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"Springboot","slug":"Springboot","link":"/tags/Springboot/"},{"name":"正则","slug":"正则","link":"/tags/%E6%AD%A3%E5%88%99/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"}],"categories":[{"name":"SQL","slug":"SQL","link":"/categories/SQL/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"},{"name":"Blog","slug":"Blog","link":"/categories/Blog/"},{"name":"学习笔记","slug":"学习笔记","link":"/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"知识区","slug":"知识区","link":"/categories/%E7%9F%A5%E8%AF%86%E5%8C%BA/"}]}